import streamlit as st
from datetime import datetime
import os
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from PIL import Image
import base64
import requests
try:
    from openpyxl import load_workbook
except ImportError:
    openpyxl = None

# ==== CONFIG SECTION ====
# –ü—É—Ç—å –∫ Excel —Å –ª–µ–π–∫–∞–º–∏ –∏ –∑–≤—ñ—Ç–∞–º–∏. –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –∞–±—Å–æ–ª—é—Ç–Ω–∏–π —à–ª—è—Ö –¥–æ –ø–∞–ø–∫–∏ –∑ –∫–æ–¥–æ–º
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
EXCEL_FILE_PATH = os.path.join(SCRIPT_DIR, "LakeHouse.xlsx")

# GitHub URL –¥–ª—è —Ñ–∞–π–ª—É (raw —Ñ–æ—Ä–º–∞—Ç)
GITHUB_RAW_URL = "https://raw.githubusercontent.com/AleksandraFilatova/knowledge-transfer-app/main/LakeHouse.xlsx"

# ======= –§—É–Ω–∫—Ü—ñ—è –¥–ª—è —á–∏—Ç–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –∑ Excel =========
@st.cache_data(ttl=300)
def load_lakes_and_reports(excel_path):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î –¥–∞–Ω—ñ –∑ Excel —Ñ–∞–π–ª—É
    """
    try:
        xl = pd.ExcelFile(excel_path)
        available_sheets = xl.sheet_names
        
        lakes_df = None
        reports_df = None
        
        # –®—É–∫–∞—î–º–æ –ª–∏—Å—Ç –∑ –ª–µ–π–∫–∞–º–∏ (–º–æ–∂–ª–∏–≤—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –Ω–∞–∑–≤)
        lake_sheet_names = ['Lakes']
        for sheet_name in lake_sheet_names:
            if sheet_name in available_sheets:
                lakes_df = pd.read_excel(xl, sheet_name)
                break
        
        # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏–π –ª–∏—Å—Ç, —Å–ø—Ä–æ–±—É—î–º–æ –¥—Ä—É–≥–∏–π –ª–∏—Å—Ç (—è–∫—â–æ —î)
        if lakes_df is None and len(available_sheets) > 1:
            lakes_df = pd.read_excel(xl, available_sheets[1])
        elif lakes_df is None and available_sheets:
            lakes_df = pd.read_excel(xl, available_sheets[0])
        
        # –®—É–∫–∞—î–º–æ –ª–∏—Å—Ç –∑—ñ –∑–≤—ñ—Ç–∞–º–∏
        report_sheet_names = ['Reports', 'reports', 'report', '–∑–≤—ñ—Ç–∏', 'Power BI']
        for sheet_name in report_sheet_names:
            if sheet_name in available_sheets:
                reports_df = pd.read_excel(xl, sheet_name)
                break
        
        # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏–π –ª–∏—Å—Ç, –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –ø–µ—Ä—à–∏–π –ª–∏—Å—Ç
        if reports_df is None and available_sheets:
            reports_df = pd.read_excel(xl, available_sheets[0])
        
        # –í–∏—Ç—è–≥—É—î–º–æ –Ω–∞–∑–≤–∏
        lakes_names = []
        reports_names = []
        
        if lakes_df is not None and not lakes_df.empty:
            # –®—É–∫–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏ (–º–æ–∂–ª–∏–≤—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏)
            name_columns = ['LakeHouse', 'name', 'Name', '–Ω–∞–∑–≤–∞', '–ù–∞–∑–≤–∞', 'lake_name', 'Lake Name', 'Lakehouse']
            name_col = None
            for col in name_columns:
                if col in lakes_df.columns:
                    name_col = col
                    break
            
            if name_col:
                lakes_names = list(lakes_df[name_col].dropna())
            else:
                # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏, –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –ø–µ—Ä—à—É –∫–æ–ª–æ–Ω–∫—É
                lakes_names = list(lakes_df.iloc[:, 0].dropna())
        
        if reports_df is not None and not reports_df.empty:
            name_columns = ['name', 'Name', '–Ω–∞–∑–≤–∞', '–ù–∞–∑–≤–∞', 'report_name', 'Report Name']
            name_col = None
            for col in name_columns:
                if col in reports_df.columns:
                    name_col = col
                    break
            
            if name_col:
                reports_names = list(reports_df[name_col].dropna())
            else:
                reports_names = list(reports_df.iloc[:, 0].dropna())
        
        return lakes_names, reports_names, lakes_df, reports_df
        
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ —Ñ–∞–π–ª—É: {e}")
        return [], [], None, None

def analyze_lakes_data(lakes_df):
    """
    –ê–Ω–∞–ª—ñ–∑—É—î –¥–∞–Ω—ñ –ª–µ–π–∫—ñ–≤ —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    if lakes_df is None or lakes_df.empty:
        return {
            'total_lakes': 0,
            'columns': [],
            'missing_data': {},
            'unique_values': {}
        }
    
    analysis = {
        'total_lakes': len(lakes_df),
        'columns': list(lakes_df.columns),
        'missing_data': {},
        'unique_values': {}
    }
    
    # –ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö
    for col in lakes_df.columns:
        missing_count = lakes_df[col].isna().sum()
        analysis['missing_data'][col] = missing_count
    
    # –ê–Ω–∞–ª—ñ–∑ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å –¥–ª—è –∫–æ–∂–Ω–æ—ó –∫–æ–ª–æ–Ω–∫–∏
    for col in lakes_df.columns:
        if lakes_df[col].dtype == 'object':  # –¢–µ–∫—Å—Ç–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏
            analysis['unique_values'][col] = lakes_df[col].value_counts().to_dict()
    
    return analysis

def display_image_from_path(image_path, caption=None, width=None):
    """
    –í—ñ–¥–æ–±—Ä–∞–∂–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ —Ñ–∞–π–ª–æ–≤–æ–≥–æ —à–ª—è—Ö—É –∞–±–æ URL
    """
    try:
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ü–µ URL
        if image_path.startswith(('http://', 'https://')):
            st.image(image_path, caption=caption, width=width)
        elif os.path.exists(image_path):
            image = Image.open(image_path)
            st.image(image, caption=caption, width=width)
        else:
            st.warning(f"‚ö†Ô∏è –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {image_path}")
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {e}")

def display_image_from_base64(base64_string, caption=None, width=None):
    """
    –í—ñ–¥–æ–±—Ä–∞–∂–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ base64 —Ä—è–¥–∫–∞
    """
    try:
        # –î–µ–∫–æ–¥—É—î–º–æ base64
        image_data = base64.b64decode(base64_string)
        st.image(image_data, caption=caption, width=width)
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –¥–µ–∫–æ–¥—É–≤–∞–Ω–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {e}")

def process_text_with_images(text):
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–µ–∫—Å—Ç —Ç–∞ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, —è–∫—â–æ –∑–Ω–∞–π–¥–µ–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –Ω–∏—Ö
    """
    if not text:
        return text
    
    # –®—É–∫–∞—î–º–æ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ —Ç–µ–∫—Å—Ç—ñ
    import re
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ—à—É–∫—É –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    image_pattern = r'\[IMAGE:(.*?)\]'
    matches = re.findall(image_pattern, text)
    
    if matches:
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
        parts = re.split(image_pattern, text)
        
        for i, part in enumerate(parts):
            if i % 2 == 0:  # –¢–µ–∫—Å—Ç
                if part.strip():
                    st.markdown(part)
            else:  # –®–ª—è—Ö –¥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                image_path = part.strip()
        # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ü–µ –ª–æ–∫–∞–ª—å–Ω–∏–π —à–ª—è—Ö, —ñ –∑–∞–º—ñ–Ω—é—î–º–æ –Ω–∞ GitHub URL
        if image_path.startswith('C:\\') and 'PL-notebook.png' in image_path:
            # –ó–∞–º—ñ–Ω—é—î–º–æ –ª–æ–∫–∞–ª—å–Ω–∏–π —à–ª—è—Ö –Ω–∞ GitHub URL
            github_url = "https://raw.githubusercontent.com/AleksandraFilatova/knowledge-transfer-app/main/Image/Sac-notebook.PNG"
            display_image_from_path(github_url, width=600)
        elif 'github.com' in image_path and '/blob/' in image_path:
            # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–ø—Ä–∞–≤–ª—è—î–º–æ GitHub blob URL –Ω–∞ raw URL
            raw_url = image_path.replace('github.com', 'raw.githubusercontent.com').replace('/blob/', '/')
            display_image_from_path(raw_url, width=600)
        else:
            display_image_from_path(image_path, width=600)
    else:
        # –Ø–∫—â–æ –Ω–µ–º–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω—å, –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—É—î–º–æ —Ç–µ–∫—Å—Ç
        st.markdown(text)

def download_file_from_github(url, local_path):
    """
    –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î —Ñ–∞–π–ª –∑ GitHub
    """
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        with open(local_path, 'wb') as f:
            f.write(response.content)
        return True
    except Exception as e:
        return False

def save_data_to_excel(df, filename, lakes_table=None, reports_table=None):
    """
    –ó–±–µ—Ä—ñ–≥–∞—î DataFrame –≤ Excel —Ñ–∞–π–ª –∑ –ø—ñ–¥—Ç—Ä–∏–º–∫–æ—é –º–Ω–æ–∂–∏–Ω–Ω–∏—Ö –ª–∏—Å—Ç—ñ–≤
    """
    try:
        # –í—ñ–¥–∫—Ä–∏–≤–∞—î–º–æ —ñ—Å–Ω—É—é—á–∏–π —Ñ–∞–π–ª, —è–∫—â–æ –≤—ñ–Ω —î
        if os.path.exists(filename):
            from openpyxl import load_workbook
            try:
                # –°–ø—Ä–æ–±—É—î–º–æ –∑—á–∏—Ç–∞—Ç–∏ —ñ—Å–Ω—É—é—á–∏–π —Ñ–∞–π–ª
                existing_df = pd.ExcelFile(filename)
                
                # –Ø–∫—â–æ –≤ —Ñ–∞–π–ª—ñ —î –ª–∏—Å—Ç "Reports", –∑–±–µ—Ä—ñ–≥–∞—î–º–æ –π–æ–≥–æ
                if 'Reports' in existing_df.sheet_names and reports_table is not None:
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑ –æ–±–æ–º–∞ –ª–∏—Å—Ç–∞–º–∏
                    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                        df.to_excel(writer, sheet_name='Lakes', index=False)
                        reports_table.to_excel(writer, sheet_name='Reports', index=False)
                else:
                    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ —Ç—ñ–ª—å–∫–∏ –æ–Ω–æ–≤–ª–µ–Ω–∏–π –ª–∏—Å—Ç
                    with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                        df.to_excel(writer, sheet_name='Lakes', index=False)
                        if reports_table is not None:
                            reports_table.to_excel(writer, sheet_name='Reports', index=False)
            except:
                # –Ø–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –≤—ñ–¥–∫—Ä–∏—Ç–∏, –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–∑–∞–ø–∏—à–µ–º–æ
                with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                    df.to_excel(writer, sheet_name='Lakes', index=False)
                    if reports_table is not None:
                        reports_table.to_excel(writer, sheet_name='Reports', index=False)
        else:
            # –Ø–∫—â–æ —Ñ–∞–π–ª—É –Ω–µ–º–∞—î, —Å—Ç–≤–æ—Ä—é—î–º–æ –Ω–æ–≤–∏–π
            with pd.ExcelWriter(filename, engine='openpyxl') as writer:
                df.to_excel(writer, sheet_name='Lakes', index=False)
                if reports_table is not None:
                    reports_table.to_excel(writer, sheet_name='Reports', index=False)
        
        return True, filename
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—ñ: {e}")
        return False, None

def create_lakes_visualization(lakes_df):
    """
    –°—Ç–≤–æ—Ä—é—î –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥–ª—è –¥–∞–Ω–∏—Ö –ª–µ–π–∫—ñ–≤
    """
    if lakes_df is None or lakes_df.empty:
        return None
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
    charts = {}
    
    # 1. –ö—Ä—É–≥–æ–≤–∞ –¥—ñ–∞–≥—Ä–∞–º–∞ –¥–ª—è —Å—Ç–∞—Ç—É—Å—É (—è–∫—â–æ —î –∫–æ–ª–æ–Ω–∫–∞ Status)
    if 'Status' in lakes_df.columns:
        status_counts = lakes_df['Status'].value_counts()
        fig_pie = px.pie(
            values=status_counts.values,
            names=status_counts.index,
            title="–†–æ–∑–ø–æ–¥—ñ–ª –ª–µ–π–∫—ñ–≤ –∑–∞ —Å—Ç–∞—Ç—É—Å–æ–º"
        )
        charts['status_pie'] = fig_pie
    
    # 2. –ì—ñ—Å—Ç–æ–≥—Ä–∞–º–∞ –¥–ª—è —á–∞—Å—Ç–æ—Ç–∏ –æ–Ω–æ–≤–ª–µ–Ω—å (—è–∫—â–æ —î –∫–æ–ª–æ–Ω–∫–∞ Update_Frequency)
    if 'Update_Frequency' in lakes_df.columns:
        fig_bar = px.bar(
            x=lakes_df['Update_Frequency'].value_counts().index,
            y=lakes_df['Update_Frequency'].value_counts().values,
            title="–ß–∞—Å—Ç–æ—Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω—å –ª–µ–π–∫—ñ–≤"
        )
        charts['frequency_bar'] = fig_bar
    
    # 3. Treemap –¥–ª—è —Ä–æ–∑–ø–æ–¥—ñ–ª—É –ø–æ —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Å—Ç–æ—Ä–∞—Ö (—è–∫—â–æ —î –∫–æ–ª–æ–Ω–∫–∞ Workspace)
    if 'Workspace' in lakes_df.columns:
        fig_treemap = px.treemap(
            lakes_df,
            path=['Workspace'],
            title="–†–æ–∑–ø–æ–¥—ñ–ª –ª–µ–π–∫—ñ–≤ –ø–æ —Ä–æ–±–æ—á–∏—Ö –ø—Ä–æ—Å—Ç–æ—Ä–∞—Ö"
        )
        charts['workspace_treemap'] = fig_treemap
    
    return charts

def create_lake_details_card(lake_row):
    """
    –°—Ç–≤–æ—Ä—é—î –¥–µ—Ç–∞–ª—å–Ω—É –∫–∞—Ä—Ç–∫—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ª–µ–π–∫–∞
    """
    if lake_row is None or lake_row.empty:
        return "–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –ø—Ä–æ –ª–µ–π–∫"
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ HTML –∫–∞—Ä—Ç–∫—É –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é
    card_html = """
    <div style="
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        margin: 10px 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    ">
        <h3 style="margin: 0 0 15px 0; color: white;">üèûÔ∏è {lake_name}</h3>
    """.format(lake_name=lake_row.get('LakeHouse', '–ù–µ–≤—ñ–¥–æ–º–∏–π –ª–µ–π–∫'))
    
    # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ —É—Å—ñ—Ö –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
    for col in lake_row.index:
        if pd.notna(lake_row[col]) and col not in ['LakeHouse', 'Folder', 'Element', '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫', '–í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω']: # –í–∏–∫–ª—é—á–∞—î–º–æ –≤–∂–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω—ñ –∞–±–æ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏
            value = lake_row[col]
            # –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ –Ω–∞–∑–≤–∏ –∫–æ–ª–æ–Ω–æ–∫ –¥–ª—è –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è
            display_col_name = {
                'Type': '–¢–∏–ø',
                '–û–ø–∏—Å': '–û–ø–∏—Å',
                '–û–Ω–æ–≤–ª–µ–Ω–Ω—è': '–û–Ω–æ–≤–ª–µ–Ω–Ω—è',
                '–û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ': '–û—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ',
            }.get(col, col) # –Ø–∫—â–æ –Ω–µ–º–∞—î –ø–µ—Ä–µ–∫–ª–∞–¥—É, –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—å–Ω—É –Ω–∞–∑–≤—É
            card_html += f"<p style=\"margin: 5px 0;\"><strong>{display_col_name}:</strong> {value}</p>"
    
    card_html += "</div>"
    return card_html

# ==================== –ù–ê–°–¢–†–û–ô–ö–ò –°–¢–û–†–Ü–ù–ö–ò ====================
st.set_page_config(
    page_title="Knowledge Transfer App",
    page_icon="üß†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ==================== –ù–ê–í–Ü–ì–ê–¶–Ü–Ø ====================
st.sidebar.title("üóÇÔ∏è –ù–∞–≤—ñ–≥–∞—Ü—ñ—è")
st.sidebar.markdown("### –û–±–µ—Ä—ñ—Ç—å —Ä–æ–∑–¥—ñ–ª:")

section = st.sidebar.radio(
    "",
    ["üè† –ì–æ–ª–æ–≤–Ω–∞", 
     "üíß –û–Ω–æ–≤–ª–µ–Ω–Ω—è LakeHouses", 
     "üìä –û–Ω–æ–≤–ª–µ–Ω–Ω—è PowerBI Report",
     "‚úèÔ∏è –†–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö",
     "üìû –ö–æ–Ω—Ç–∞–∫—Ç–∏ —Ç–∞ —Ä–µ—Å—É—Ä—Å–∏"]
)

st.sidebar.markdown("---")
st.sidebar.info(f"üìÖ –û—Å—Ç–∞–Ω–Ω—î –æ–Ω–æ–≤–ª–µ–Ω–Ω—è:\n{datetime.now().strftime('%d.%m.%Y')}")


# === –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ô –ó–ê–ü–†–û–° —Ç–∞–±–ª–∏—Ü—ã Excel –¥–ª—è Lakes & reports ===
# –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ñ–∞–π–ª —ñ—Å–Ω—É—î –ª–æ–∫–∞–ª—å–Ω–æ
if os.path.exists(EXCEL_FILE_PATH):
    lakes, reports, lakes_table, reports_table = load_lakes_and_reports(EXCEL_FILE_PATH)
    # –ü–æ–∫–∞–∑—É—î–º–æ –ø–æ–≤—ñ–¥–æ–º–ª–µ–Ω–Ω—è, –¥–µ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –¥–∞–Ω—ñ
    abs_path = os.path.abspath(EXCEL_FILE_PATH)
    st.sidebar.success(f"üìÇ –§–∞–π–ª: `{abs_path}`")
else:
    # –Ø–∫—â–æ —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –ª–æ–∫–∞–ª—å–Ω–æ, —Å–ø—Ä–æ–±—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑ GitHub
    if download_file_from_github(GITHUB_RAW_URL, EXCEL_FILE_PATH):
        lakes, reports, lakes_table, reports_table = load_lakes_and_reports(EXCEL_FILE_PATH)
        abs_path = os.path.abspath(EXCEL_FILE_PATH)
        st.sidebar.success(f"‚úÖ –§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ –∑ GitHub: `{abs_path}`")
    else:
        # –Ø–∫—â–æ –Ω–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –∑ GitHub, –ø—Ä–æ–ø–æ–Ω—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –≤—Ä—É—á–Ω—É
        st.warning("‚ö†Ô∏è –§–∞–π–ª LakeHouse.xlsx –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª:")
        uploaded_file = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ Excel —Ñ–∞–π–ª", type=['xlsx', 'xls'])
        
        if uploaded_file is not None:
            # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π —Ñ–∞–π–ª
            with open(EXCEL_FILE_PATH, "wb") as f:
                f.write(uploaded_file.getbuffer())
            st.success("‚úÖ –§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ! –û–Ω–æ–≤–ª—é—î–º–æ –¥–∞–Ω—ñ...")
            lakes, reports, lakes_table, reports_table = load_lakes_and_reports(EXCEL_FILE_PATH)
            abs_path = os.path.abspath(EXCEL_FILE_PATH)
            st.sidebar.info(f"üìÇ –õ–æ–∫–∞–ª—å–Ω–∏–π —Ñ–∞–π–ª: `{abs_path}`")
        else:
            # –ü–æ–∫–∞–∑—É—î–º–æ –∑–∞–≥–ª—É—à–∫—É
            lakes, reports, lakes_table, reports_table = [], [], None, None
            st.info("üëÜ –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –ø–æ—á–∞—Ç–∫—É —Ä–æ–±–æ—Ç–∏")

# ==================== –ì–û–õ–û–í–ù–ê –°–¢–û–†–Ü–ù–ö–ê ====================
if section == "üè† –ì–æ–ª–æ–≤–Ω–∞":
    st.header("–í—ñ—Ç–∞—î–º–æ! üëã")
    st.markdown("""
    –¶—è –±–∞–∑–∞ –∑–Ω–∞–Ω—å –º—ñ—Å—Ç–∏—Ç—å –≤—Å—é –Ω–µ–æ–±—Ö—ñ–¥–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –¥–ª—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ —Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è 
    –Ω–∞—à–∏—Ö LakeHouses —Ç–∞ Power BI Reports.

    **‚ö°Ô∏è –¢–µ–ø–µ—Ä —Å–ø–∏—Å–æ–∫ –ª–µ–π–∫—ñ–≤ —ñ –∑–≤—ñ—Ç—ñ–≤ –∑—á–∏—Ç—É—î—Ç—å—Å—è –∑ —Ç–∞–±–ª–∏—Ü—ñ Excel**  
    –ú–æ–∂–Ω–∞ –ª–µ–≥–∫–æ –∫–æ—Ä–∏–≥—É–≤–∞—Ç–∏ —Å–∫–ª–∞–¥ –±–µ–∑ –∑–º—ñ–Ω–∏ –∫–æ–¥—É!
    
    ### üìù –Ø–∫ –æ–Ω–æ–≤–∏—Ç–∏ –¥–∞–Ω—ñ:
    1. **–ü–µ—Ä–µ–π–¥—ñ—Ç—å –≤ —Ä–æ–∑–¥—ñ–ª "–†–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö"** (–≤ –º–µ–Ω—é –∑–ª—ñ–≤–∞)
    2. **–†–µ–¥–∞–≥—É–π—Ç–µ –¥–∞–Ω—ñ –ø—Ä—è–º–æ –≤ —Ç–∞–±–ª–∏—Ü—ñ** - –∑–º—ñ–Ω–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ
    3. **–î–æ–¥–∞–≤–∞–π—Ç–µ –Ω–æ–≤—ñ –∑–∞–ø–∏—Å–∏** —á–µ—Ä–µ–∑ —Ñ–æ—Ä–º—É
    4. **–ó–º—ñ–Ω–∏ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—é—Ç—å—Å—è** –º–∏—Ç—Ç—î–≤–æ –¥–ª—è –≤—Å—ñ—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
    
    **Excel —Ñ–∞–π–ª:** `{}`  
    **–ü–æ–≤–Ω–∏–π —à–ª—è—Ö:** `{}`  
    """.format(EXCEL_FILE_PATH, os.path.abspath(EXCEL_FILE_PATH)))
    col1, col2 = st.columns(2)
    with col1:
        st.metric("üèûÔ∏è Data Lakes", len(lakes) if lakes else 0)
    with col2:
        st.metric("üìä Power BI –∑–≤—ñ—Ç–∏", len(reports) if reports else 0)

# ==================== –û–ù–û–í–õ–ï–ù–ù–Ø DATA LAKES ====================
elif section == "üíß –û–Ω–æ–≤–ª–µ–Ω–Ω—è LakeHouses":
    st.header("üíß –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –ø–æ –æ–Ω–æ–≤–ª–µ–Ω–Ω—é LakeHouses")
    
    # –ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö –±—É–¥–µ –ø–æ–∫–∞–∑–∞–Ω–æ –ø—ñ—Å–ª—è –≤–∏–±–æ—Ä—É –ª–µ–π–∫–∞
    
    # –û—Ç—Ä–∏–º—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –Ω–∞–∑–≤–∏ –ª–µ–π–∫—ñ–≤ (–±–µ–∑ –¥—É–±–ª—é–≤–∞–Ω–Ω—è)
    unique_lakes = []
    if lakes_table is not None and not lakes_table.empty:
        # –®—É–∫–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏ –ª–µ–π–∫—ñ–≤
        name_columns = ['LakeHouse', 'name', 'Name', '–Ω–∞–∑–≤–∞', '–ù–∞–∑–≤–∞', 'lake_name', 'Lake Name', 'Lakehouse']
        name_col = None
        for col in name_columns:
            if col in lakes_table.columns:
                name_col = col
                break
        
        if name_col:
            unique_lakes = list(lakes_table[name_col].dropna().unique())
        else:
            unique_lakes = list(lakes_table.iloc[:, 0].dropna().unique())
    
    # –î–æ–¥–∞—î–º–æ –æ–ø—Ü—ñ—ó –¥–ª—è –≤–∏–±–æ—Ä—É
    lake_select_options = ["–í—Å—ñ –ª–µ–π–∫–∏"] + unique_lakes + ["üìä –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è"]
    
    lake_name = st.selectbox(
        "–û–±–µ—Ä—ñ—Ç—å Data Lake:",
        lake_select_options
    )
    
    if lake_name == "–í—Å—ñ –ª–µ–π–∫–∏":
        st.info("üëà –û–±–µ—Ä—ñ—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –ª–µ–π–∫ –∑—ñ —Å–ø–∏—Å–∫—É –≤–∏—â–µ")
        
        # –ü–æ–∫–∞–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –ª–µ–π–∫–∏ –∑ –∫–æ–ª–æ–Ω–∫–∏ LakeHouse
        if lakes_table is not None and not lakes_table.empty:
            # –û—Ç—Ä–∏–º—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –∫–æ–ª–æ–Ω–∫–∏ LakeHouse
            unique_lakes = lakes_table['LakeHouse'].dropna().unique()
            
            # –ü–æ–∫–∞–∑—É—î–º–æ –º–µ—Ç—Ä–∏–∫—É —Ç—ñ–ª—å–∫–∏ –¥–ª—è –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ª–µ–π–∫—ñ–≤
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üèûÔ∏è –£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ª–µ–π–∫—ñ–≤", len(unique_lakes))
            with col2:
                st.metric("", "")  # –ü–æ—Ä–æ–∂–Ω—è –∫–∞—Ä—Ç–∫–∞
            with col3:
                st.metric("", "")  # –ü–æ—Ä–æ–∂–Ω—è –∫–∞—Ä—Ç–∫–∞
            with col4:
                st.metric("", "")  # –ü–æ—Ä–æ–∂–Ω—è –∫–∞—Ä—Ç–∫–∞
            
            st.subheader("üìã –°–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö Data Lakes")
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∞–±–ª–∏—Ü—é —Ç—ñ–ª—å–∫–∏ –∑ 2 –∫–æ–ª–æ–Ω–∫–∞–º–∏
            if 'LakeHouse' in lakes_table.columns and '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫' in lakes_table.columns:
                # –ì—Ä—É–ø—É—î–º–æ –ø–æ LakeHouse —Ç–∞ –±–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π –∑–∞–ø–∏—Å –¥–ª—è –∫–æ–∂–Ω–æ—ó –≥—Ä—É–ø–∏
                summary_table = lakes_table.groupby('LakeHouse').first().reset_index()
                
                # –ü–æ–∫–∞–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏
                display_columns = ['LakeHouse', '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫']
                summary_display = summary_table[display_columns]
                
                st.dataframe(
                    summary_display, 
                    use_container_width=True,
                    hide_index=True
                )
                
                # –î–æ–¥–∞—î–º–æ –∫–Ω–æ–ø–∫—É –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É
                csv = summary_display.to_csv(index=False)
                st.download_button(
                    label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ CSV",
                    data=csv,
                    file_name=f"lakes_summary_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
            else:
                st.warning("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–∫–∏ 'LakeHouse' –∞–±–æ '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫'")
        else:
            st.warning("–°–ø–∏—Å–æ–∫ –ª–µ–π–∫—ñ–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π —É —Ñ–∞–π–ª—ñ Excel!")
    
    elif lake_name == "üìä –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è":
        st.subheader("üìä –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ª–µ–π–∫—ñ–≤")
        
        if lakes_table is not None and not lakes_table.empty:
            # –ü–æ–∫–∞–∑—É—î–º–æ –∞–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö
            analysis = analyze_lakes_data(lakes_table)
            
            # –ü–æ–∫–∞–∑—É—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üèûÔ∏è –í—Å—å–æ–≥–æ –ª–µ–π–∫—ñ–≤", analysis['total_lakes'])
            with col2:
                st.metric("üìä –ö–æ–ª–æ–Ω–æ–∫ –¥–∞–Ω–∏—Ö", len(analysis['columns']))
            with col3:
                missing_total = sum(analysis['missing_data'].values())
                st.metric("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å", missing_total)
            with col4:
                st.metric("üìÖ –û—Å—Ç–∞–Ω–Ω—î –æ–Ω–æ–≤–ª–µ–Ω–Ω—è", datetime.now().strftime('%d.%m'))
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
            charts = create_lakes_visualization(lakes_table)
            
            if charts:
                st.subheader("üìà –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –¥–æ—Å—Ç—É–ø–Ω—ñ –¥—ñ–∞–≥—Ä–∞–º–∏
                for chart_name, chart in charts.items():
                    if chart_name == 'status_pie':
                        st.plotly_chart(chart, use_container_width=True)
                    elif chart_name == 'frequency_bar':
                        st.plotly_chart(chart, use_container_width=True)
                    elif chart_name == 'workspace_treemap':
                        st.plotly_chart(chart, use_container_width=True)
            
            # –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
            st.subheader("üîç –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑")
            
            # –ê–Ω–∞–ª—ñ–∑ –ø—Ä–æ–ø—É—â–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö
            if any(analysis['missing_data'].values()):
                st.subheader("‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω—ñ –¥–∞–Ω—ñ")
                missing_df = pd.DataFrame(list(analysis['missing_data'].items()), columns=['–ö–æ–ª–æ–Ω–∫–∞', '–ü—Ä–æ–ø—É—â–µ–Ω–æ'])
                missing_df = missing_df[missing_df['–ü—Ä–æ–ø—É—â–µ–Ω–æ'] > 0]
                if not missing_df.empty:
                    st.dataframe(missing_df, use_container_width=True)
                else:
                    st.success("‚úÖ –ü—Ä–æ–ø—É—â–µ–Ω–∏—Ö –¥–∞–Ω–∏—Ö –Ω–µ–º–∞—î!")
            
            # –ê–Ω–∞–ª—ñ–∑ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
            if analysis['unique_values']:
                st.subheader("üìä –£–Ω—ñ–∫–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è")
                for col, values in analysis['unique_values'].items():
                    if values:
                        st.write(f"**{col}:**")
                        values_df = pd.DataFrame(list(values.items()), columns=['–ó–Ω–∞—á–µ–Ω–Ω—è', '–ö—ñ–ª—å–∫—ñ—Å—Ç—å'])
                        st.dataframe(values_df, use_container_width=True)
        else:
            st.warning("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É!")
    
    else:
        # –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ lake
        if lakes_table is not None and not lakes_table.empty:
            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –≤–∏–±—Ä–∞–Ω–æ–≥–æ –ª–µ–π–∫–∞
            lake_data = None
            
            # –®—É–∫–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏ –ª–µ–π–∫—ñ–≤
            name_columns = ['LakeHouse', 'name', 'Name', '–Ω–∞–∑–≤–∞', '–ù–∞–∑–≤–∞', 'lake_name', 'Lake Name', 'Lakehouse']
            name_col = None
            for col in name_columns:
                if col in lakes_table.columns:
                    if lake_name in lakes_table[col].values:
                        name_col = col
                        lake_data = lakes_table[lakes_table[col] == lake_name]
                        break
            
            # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∑–∞ –Ω–∞–∑–≤–æ—é, –∞–ª–µ —î —Ç—ñ–ª—å–∫–∏ –æ–¥–∏–Ω —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π –ª–µ–π–∫ - –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –≤—Å—ñ –¥–∞–Ω—ñ
            if lake_data is None or lake_data.empty:
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —î —Ç—ñ–ª—å–∫–∏ –æ–¥–∏–Ω —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π –ª–µ–π–∫
                unique_lakes = []
                for col in name_columns:
                    if col in lakes_table.columns:
                        unique_lakes = list(lakes_table[col].dropna().unique())
                        if len(unique_lakes) == 1:
                            lake_data = lakes_table
                            st.info(f"üí° –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —î–¥–∏–Ω–∏–π –ª–µ–π–∫: {unique_lakes[0]}")
                            break
            
            if lake_data is not None and not lake_data.empty:
                st.success(f"üèûÔ∏è –í–∏–±—Ä–∞–Ω–æ –ª–µ–π–∫: **{lake_name}**")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –∞–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ª–µ–π–∫–∞
                if lakes_table is not None and not lakes_table.empty:
                    # –†–∞—Ö—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –ª–µ–π–∫–∏ –∑ –∫–æ–ª–æ–Ω–∫–∏ LakeHouse
                    unique_lakes_count = lakes_table['LakeHouse'].nunique()
                    
                    # –†–∞—Ö—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ –∫–æ–ª–æ–Ω–∫–∏ Element
                    unique_elements_count = lakes_table['Element'].nunique() if 'Element' in lakes_table.columns else 0
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("üèûÔ∏è –í—Å—å–æ–≥–æ –ª–µ–π–∫—ñ–≤", unique_lakes_count)
                    with col2:
                        st.metric("üß© –ö—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ª–µ–º–µ–Ω—Ç—ñ–≤", unique_elements_count)
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ª–µ–π–∫ –∑ –∫–æ–ª–æ–Ω–∫–∏ "–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫"
                st.subheader("‚ÑπÔ∏è –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫")
                if '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫' in lake_data.columns and pd.notna(lake_data['–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫'].iloc[0]):
                    st.info(lake_data['–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫'].iloc[0])
                else:
                    st.info("–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫ –Ω–µ –Ω–∞–¥–∞–Ω–∞")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ª–µ–π–∫–∞ —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ —î –∫–æ–ª–æ–Ω–∫–∞ Folder
                if 'Folder' in lake_data.columns:
                    st.subheader("üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ª–µ–π–∫–∞")
                    
                    # –û—Ç—Ä–∏–º—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –ø–∞–ø–∫–∏
                    unique_folders = lake_data['Folder'].dropna().unique()
                    
                    if len(unique_folders) > 0:
                        st.write("**–î–æ—Å—Ç—É–ø–Ω—ñ –ø–∞–ø–∫–∏:**")
                        
                        # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–Ω–æ–ø–∫–∏ –¥–ª—è –ø–∞–ø–æ–∫ –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
                        cols = st.columns(min(3, len(unique_folders)))
                        selected_folder = None
                        
                        for i, folder in enumerate(unique_folders):
                            with cols[i % 3]:
                                if st.button(f"üìÇ {folder}", key=f"folder_{i}"):
                                    selected_folder = folder
                        
                        # –ü–æ–∫–∞–∑—É—î–º–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –≤–∏–±—Ä–∞–Ω–æ—ó –ø–∞–ø–∫–∏
                        if selected_folder:
                            st.success(f"üìÇ –í–∏–±—Ä–∞–Ω–æ –ø–∞–ø–∫—É: **{selected_folder}**")
                            
                            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –¥–∞–Ω—ñ –ø–æ –≤–∏–±—Ä–∞–Ω—ñ–π –ø–∞–ø—Ü—ñ
                            folder_data = lake_data[lake_data['Folder'] == selected_folder]
                            
                            # –ü–æ–∫–∞–∑—É—î–º–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –ø–∞–ø–∫–∏ (—Ç—ñ–ª—å–∫–∏ —Å—Ç–æ–≤–ø—Ü—ñ –∑ 3 –ø–æ 8)
                            st.subheader("üß© –ï–ª–µ–º–µ–Ω—Ç–∏ –ø–∞–ø–∫–∏")
                            
                            # –í–∏–±–∏—Ä–∞—î–º–æ —Å—Ç–æ–≤–ø—Ü—ñ –∑ 3 –ø–æ 8 (—ñ–Ω–¥–µ–∫—Å–∏ 2-7), –∞–ª–µ –≤–∏–∫–ª—é—á–∞—î–º–æ URL
                            display_columns = folder_data.columns[2:8]
                            # –í–∏–∫–ª—é—á–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É URL –∑ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è, —è–∫—â–æ –≤–æ–Ω–∞ —î
                            if 'URL' in display_columns:
                                display_columns = [col for col in display_columns if col != 'URL']
                            
                            if 'Element' in display_columns:
                                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —î –∫–æ–ª–æ–Ω–∫–∞ URL
                                if 'URL' in folder_data.columns:
                                    # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–ø—ñ—é –¥–ª—è –º–æ–¥–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
                                    elements_df_display = folder_data[display_columns].copy()
                                    
                                    # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–æ–≤–Ω–∏–∫ URL –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞ (–∑–∞ —ñ–Ω–¥–µ–∫—Å–æ–º)
                                    url_dict = {}
                                    for idx, row in folder_data.iterrows():
                                        url_value = row.get('URL', '')
                                        if pd.notna(url_value) and url_value.strip():
                                            url_dict[idx] = url_value.strip()
                                    
                                    # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ —Å—Ç–æ–≤–ø–µ—Ü—å 'Element' –Ω–∞ –∫–ª—ñ–∫–∞–±–µ–ª—å–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è
                                    def create_link(row_data):
                                        element_name = row_data['Element']
                                        row_idx = row_data.name  # –û—Ç—Ä–∏–º—É—î–º–æ —ñ–Ω–¥–µ–∫—Å —Ä—è–¥–∫–∞
                                        
                                        if row_idx in url_dict:
                                            url = url_dict[row_idx]
                                            return f'<a href="{url}" target="_blank" style="color: #1f77b4; text-decoration: underline;">{element_name}</a>'
                                        else:
                                            return element_name
                                    
                                    # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—é –¥–æ –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞
                                    elements_df_display['Element'] = elements_df_display.apply(create_link, axis=1)
                                    
                                    # –ü–æ–∫–∞–∑—É—î–º–æ —Ç–∞–±–ª–∏—Ü—é –∑ HTML –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º–∏
                                    st.markdown(elements_df_display.to_html(escape=False), unsafe_allow_html=True)
                                    
                                    # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ—Å–∏–ª–∞–Ω—å
                                    active_links = len(url_dict)
                                    if active_links > 0:
                                        st.info(f"üîó {active_links} –∑ {len(folder_data)} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –º–∞—é—Ç—å –∞–∫—Ç–∏–≤–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è")
                                else:
                                    # –Ø–∫—â–æ –Ω–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏ URL, –ø–æ–∫–∞–∑—É—î–º–æ –∑–≤–∏—á–∞–π–Ω—É —Ç–∞–±–ª–∏—Ü—é
                                    st.dataframe(folder_data[display_columns], use_container_width=True, hide_index=True)
                                    st.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'URL' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∫–∞–∑—É—î–º–æ –∑–≤–∏—á–∞–π–Ω—É —Ç–∞–±–ª–∏—Ü—é.")
                            else:
                                st.dataframe(folder_data[display_columns], use_container_width=True, hide_index=True)
                            
                            # –î–æ–¥–∞—î–º–æ —Å–µ–∫—Ü—ñ—é "–í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω"
                            st.subheader("üìù –í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω")
                            changes_col = '–í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω'
                            if changes_col in folder_data.columns and pd.notna(folder_data[changes_col].iloc[0]):
                                with st.expander("–ü–æ–∫–∞–∑–∞—Ç–∏ –¥–µ—Ç–∞–ª—ñ –∑–º—ñ–Ω", expanded=True):
                                    changes_text = folder_data[changes_col].iloc[0]
                                    # –û–±—Ä–æ–±–ª—è—î–º–æ —Ç–µ–∫—Å—Ç –∑ –º–æ–∂–ª–∏–≤–∏–º–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏
                                    process_text_with_images(changes_text)
                            else:
                                st.info("–ù–µ–º–∞—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –≤–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω –¥–ª—è —Ü—ñ—î—ó –ø–∞–ø–∫–∏.")
                        else:
                            st.info("üëÜ –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å –Ω–∞ –ø–∞–ø–∫—É –≤–∏—â–µ, —â–æ–± –ø–æ–±–∞—á–∏—Ç–∏ —ó—ó –µ–ª–µ–º–µ–Ω—Ç–∏")
                    else:
                        st.warning("‚ö†Ô∏è –ü–∞–ø–∫–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –¥–∞–Ω–∏—Ö")
                else:
                    # –Ø–∫—â–æ –Ω–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏ Folder, –ø–æ–∫–∞–∑—É—î–º–æ –≤—Å—é —Ç–∞–±–ª–∏—Ü—é
                    st.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'Folder' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∫–∞–∑—É—î–º–æ –≤—Å—ñ –¥–∞–Ω—ñ:")
                    st.dataframe(lake_data, use_container_width=True, hide_index=True)
                
                # –°–µ–∫—Ü—ñ—è "–í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω" —Ç–µ–ø–µ—Ä –ø–æ–∫–∞–∑—É—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ –ø—ñ—Å–ª—è –≤–∏–±–æ—Ä—É –ø–∞–ø–∫–∏
            else:
                st.error(f"‚ùå –õ–µ–π–∫ '{lake_name}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö!")
                st.info("üí° –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —á–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤–∫–∞–∑–∞–Ω–∞ –Ω–∞–∑–≤–∞ –ª–µ–π–∫–∞")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –¥–æ—Å—Ç—É–ø–Ω—ñ –ª–µ–π–∫–∏ –¥–ª—è –¥–æ–≤—ñ–¥–∫–∏
                if unique_lakes:
                    st.write("**–î–æ—Å—Ç—É–ø–Ω—ñ –ª–µ–π–∫–∏:**")
                    for lake in unique_lakes:
                        st.write(f"- {lake}")
        else:
            st.warning("‚ö†Ô∏è –î–∞–Ω—ñ –ª–µ–π–∫—ñ–≤ –Ω–µ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω—ñ. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ —Ñ–∞–π–ª Excel.")

# ==================== –†–ï–î–ê–ì–£–í–ê–ù–ù–Ø –î–ê–ù–ò–• ====================
elif section == "‚úèÔ∏è –†–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö":
    st.header("‚úèÔ∏è –†–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è –¥–∞–Ω–∏—Ö")
    
    if lakes_table is not None and not lakes_table.empty:
        st.subheader("üìä –ü–æ—Ç–æ—á–Ω—ñ –¥–∞–Ω—ñ")
        st.info("üí° –†–µ–¥–∞–≥—É–π—Ç–µ –¥–∞–Ω—ñ –ø—Ä—è–º–æ –≤ —Ç–∞–±–ª–∏—Ü—ñ. –ó–º—ñ–Ω–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ!")
        
        # –ü–æ–∫–∞–∑—É—î–º–æ —Ç–∞–±–ª–∏—Ü—é –¥–ª—è —Ä–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è
        edited_df = st.data_editor(
            lakes_table,
            use_container_width=True,
            num_rows="dynamic",
            key="data_editor"
        )
        
        # –ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è –ø—Ä–∏ –∑–º—ñ–Ω–∞—Ö
        if not edited_df.equals(lakes_table):
            success, saved_file = save_data_to_excel(edited_df, EXCEL_FILE_PATH, 
                                                     lakes_table=None, reports_table=reports_table)
            if success:
                # –û—á–∏—â—É—î–º–æ –∫–µ—à –ø—ñ—Å–ª—è –∑–±–µ—Ä–µ–∂–µ–Ω–Ω—è
                st.cache_data.clear()
                abs_path = os.path.abspath(saved_file)
                st.success(f"‚úÖ –ó–º—ñ–Ω–∏ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –ª–æ–∫–∞–ª—å–Ω–æ –≤: `{abs_path}`")
                st.info("üí° **–í–∞–∂–ª–∏–≤–æ:** –î–ª—è —Å–∏–Ω—Ö—Ä–æ–Ω—ñ–∑–∞—Ü—ñ—ó –∑ —ñ–Ω—à–∏–º–∏ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞–º–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –æ–Ω–æ–≤–ª–µ–Ω–∏–π —Ñ–∞–π–ª –Ω–∞ GitHub –≤—Ä—É—á–Ω—É")
                st.rerun()
        
        # –ö–Ω–æ–ø–∫–∏ –¥–ª—è –¥–æ–¥–∞—Ç–∫–æ–≤–∏—Ö –¥—ñ–π
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üîÑ –û–Ω–æ–≤–∏—Ç–∏ –¥–∞–Ω—ñ"):
                st.cache_data.clear()
                st.rerun()
        
        with col2:
            csv = edited_df.to_csv(index=False)
            st.download_button(
                label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ CSV",
                data=csv,
                file_name=f"lakes_data_{datetime.now().strftime('%Y%m%d')}.csv",
                mime="text/csv"
            )
        
        # –î–æ–¥–∞—î–º–æ –Ω–æ–≤–∏–π —Ä—è–¥–æ–∫
        st.subheader("‚ûï –î–æ–¥–∞—Ç–∏ –Ω–æ–≤–∏–π –∑–∞–ø–∏—Å")
        
        with st.form("add_new_record"):
            col1, col2 = st.columns(2)
            
            with col1:
                new_lakehouse = st.text_input("LakeHouse *", help="–û–±–æ–≤'—è–∑–∫–æ–≤–µ –ø–æ–ª–µ")
                new_folder = st.text_input("Folder *", help="–û–±–æ–≤'—è–∑–∫–æ–≤–µ –ø–æ–ª–µ")
                new_element = st.text_input("Element *", help="–û–±–æ–≤'—è–∑–∫–æ–≤–µ –ø–æ–ª–µ")
                new_url = st.text_input("URL")
            
            with col2:
                new_info = st.text_area("–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫")
                new_changes = st.text_area("–í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω")
            
            if st.form_submit_button("‚ûï –î–æ–¥–∞—Ç–∏ –∑–∞–ø–∏—Å"):
                if new_lakehouse and new_folder and new_element:
                    new_row = {
                        'LakeHouse': new_lakehouse,
                        'Folder': new_folder,
                        'Element': new_element,
                        'URL': new_url if new_url else '',
                        '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫': new_info if new_info else '',
                        '–í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω': new_changes if new_changes else ''
                    }
                    
                    # –î–æ–¥–∞—î–º–æ –Ω–æ–≤–∏–π —Ä—è–¥–æ–∫
                    new_df = pd.concat([lakes_table, pd.DataFrame([new_row])], ignore_index=True)
                    
                    success, saved_file = save_data_to_excel(new_df, EXCEL_FILE_PATH, 
                                                             lakes_table=None, reports_table=reports_table)
                    if success:
                        # –û—á–∏—â—É—î–º–æ –∫–µ—à, —â–æ–± –ø—ñ—Å–ª—è –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –Ω–æ–≤—ñ –¥–∞–Ω—ñ
                        st.cache_data.clear()
                        abs_path = os.path.abspath(saved_file)
                        st.success(f"‚úÖ –ù–æ–≤–∏–π –∑–∞–ø–∏—Å –¥–æ–¥–∞–Ω–æ —Ç–∞ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤: `{abs_path}`")
                        st.rerun()
                else:
                    st.error("‚ùå –ó–∞–ø–æ–≤–Ω—ñ—Ç—å –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ –ø–æ–ª—è: LakeHouse, Folder, Element")
    else:
        st.warning("‚ö†Ô∏è –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è —Ä–µ–¥–∞–≥—É–≤–∞–Ω–Ω—è. –°–ø–æ—á–∞—Ç–∫—É –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ Excel —Ñ–∞–π–ª.")

# ==================== –ö–û–ù–¢–ê–ö–¢–ò –¢–ê –†–ï–°–£–†–°–ò ====================
elif section == "üìû –ö–æ–Ω—Ç–∞–∫—Ç–∏ —Ç–∞ —Ä–µ—Å—É—Ä—Å–∏":
    st.header("üìû –ö–æ–Ω—Ç–∞–∫—Ç–∏ —Ç–∞ —Ä–µ—Å—É—Ä—Å–∏")
    st.subheader("üë• –ù–∞—à–∞ –∫–æ–º–∞–Ω–¥–∞")
    
    # –ö–æ–º–∞–Ω–¥–∞ –≤ –æ–¥–Ω–æ–º—É –±–ª–æ—Ü—ñ
    st.markdown("""
    ### üè¢ OurTeam
    
    **Zhovtiuk Svitlana**  
    –ö–µ—Ä—ñ–≤–Ω–∏–∫ –≥—Ä—É–ø–∏  
    üìß s.zhovtiuk@darnytsia.ua
    
    **Filatova Oleksandra**  
    –ú–µ–Ω–µ–¥–∂–µ—Ä –∑ –±—ñ–∑–Ω–µ—Å –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏  
    üìß oleksandra.filatova@darnytsia.ua
    
    **Bohdanyk Oleksandr**  
    –ú–µ–Ω–µ–¥–∂–µ—Ä –∑ –±—ñ–∑–Ω–µ—Å –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏  
    üìß o.bohdanyk@darnytsia.ua
    
    **Taranenko Oleksandr**  
    –ú–µ–Ω–µ–¥–∂–µ—Ä –∑ –±—ñ–∑–Ω–µ—Å –∞–Ω–∞–ª—ñ—Ç–∏–∫–∏  
    üìß o.taranenko@darnytsia.ua
    """)
    
    st.subheader("üîó –ö–æ—Ä–∏—Å–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        ### –í–Ω—É—Ç—Ä—ñ—à–Ω—ñ —Ä–µ—Å—É—Ä—Å–∏:
        - [SharePoint –∫–æ–º–∞–Ω–¥–∏](https://darnitsa.sharepoint.com)
        - [Azure DevOps](https://dev.azure.com/darnitsa)
        - [Power BI Service](https://app.powerbi.com)
        """)
    with col2:
        st.markdown("""
        ### –ó–æ–≤–Ω—ñ—à–Ω—ñ —Ä–µ—Å—É—Ä—Å–∏:
        - [Microsoft Learn](https://learn.microsoft.com)
        - [Power BI Community](https://community.powerbi.com)
        - [Streamlit Docs](https://docs.streamlit.io)
        """)
    

# ==================== –ö–û–ù–¢–ê–ö–¢–ò ====================

