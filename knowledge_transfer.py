import streamlit as st
from datetime import datetime
import os
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from PIL import Image
import base64

# ==== CONFIG SECTION ====
# –ü—É—Ç—å –∫ Excel —Å –ª–µ–π–∫–∞–º–∏ –∏ –∑–≤—ñ—Ç–∞–º–∏. –î–ª—è Streamlit Cloud –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –≤—ñ–¥–Ω–æ—Å–Ω–∏–π —à–ª—è—Ö
EXCEL_FILE_PATH = os.environ.get("KNOWLEDGE_TRANSFER_CONFIG_PATH", "LakeHouse.xlsx")  # –®–ª—è—Ö –¥–æ —Ç–≤–æ–≥–æ —Ñ–∞–π–ª—É

# ======= –§—É–Ω–∫—Ü—ñ—è –¥–ª—è —á–∏—Ç–∞–Ω–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –∑ Excel =========
@st.cache_data(ttl=300)
def load_lakes_and_reports(excel_path):
    """
    –°—á–∏—Ç—ã–≤–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –ª–µ–π–∫–æ–≤ –∏ –æ—Ç—á–µ—Ç–æ–≤ –∏–∑ excel-—Ñ–∞–π–ª–∞.
    –ü—ñ–¥—Ç—Ä–∏–º—É—î —Ä—ñ–∑–Ω—ñ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏ Excel —Ñ–∞–π–ª—ñ–≤ —Ç–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –≤–∏–∑–Ω–∞—á–∞—î –¥–æ—Å—Ç—É–ø–Ω—ñ –ª–∏—Å—Ç–∏.
    """
    if not os.path.exists(excel_path):
        st.warning(f"‚ö†Ô∏è –§–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {excel_path}")
        return [], [], None, None
    
    try:
        xl = pd.ExcelFile(excel_path)
        available_sheets = xl.sheet_names
        # st.info(f"üìã –î–æ—Å—Ç—É–ø–Ω—ñ –ª–∏—Å—Ç–∏ –≤ Excel: {', '.join(available_sheets)}")
        
        # –°–ø—Ä–æ–±—É—î–º–æ –∑–Ω–∞–π—Ç–∏ –ª–∏—Å—Ç–∏ –∑ –ª–µ–π–∫–∞–º–∏ —Ç–∞ –∑–≤—ñ—Ç–∞–º–∏
        lakes_df = None
        reports_df = None
        
        # –®—É–∫–∞—î–º–æ –ª–∏—Å—Ç –∑ –ª–µ–π–∫–∞–º–∏ (–º–æ–∂–ª–∏–≤—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏ –Ω–∞–∑–≤)
        lake_sheet_names = ['Lakes', 'lakes', 'lake', 'data_lakes', '–ª–µ–π–∫–∏', 'Data Lakes']
        for sheet_name in lake_sheet_names:
            if sheet_name in available_sheets:
                lakes_df = pd.read_excel(xl, sheet_name)
                # st.success(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –ª–∏—Å—Ç –∑ –ª–µ–π–∫–∞–º–∏: '{sheet_name}'")
                break
        
        # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏–π –ª–∏—Å—Ç, —Å–ø—Ä–æ–±—É—î–º–æ –¥—Ä—É–≥–∏–π –ª–∏—Å—Ç (—è–∫—â–æ —î)
        if lakes_df is None and len(available_sheets) > 1:
            lakes_df = pd.read_excel(xl, available_sheets[1])
            # st.info(f"üìã –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –¥—Ä—É–≥–∏–π –ª–∏—Å—Ç: '{available_sheets[1]}'")
        elif lakes_df is None and available_sheets:
            lakes_df = pd.read_excel(xl, available_sheets[0])
            # st.info(f"üìã –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–µ—Ä—à–∏–π –ª–∏—Å—Ç: '{available_sheets[0]}'")
        
        # –®—É–∫–∞—î–º–æ –ª–∏—Å—Ç –∑—ñ –∑–≤—ñ—Ç–∞–º–∏
        report_sheet_names = ['Reports', 'reports', 'report', '–∑–≤—ñ—Ç–∏', 'Power BI']
        for sheet_name in report_sheet_names:
            if sheet_name in available_sheets:
                reports_df = pd.read_excel(xl, sheet_name)
                # st.success(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ –ª–∏—Å—Ç –∑—ñ –∑–≤—ñ—Ç–∞–º–∏: '{sheet_name}'")
                break
        
        # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ —Å–ø–µ—Ü—ñ–∞–ª—å–Ω–∏–π –ª–∏—Å—Ç, –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –ø–µ—Ä—à–∏–π –ª–∏—Å—Ç
        if reports_df is None and available_sheets:
            reports_df = pd.read_excel(xl, available_sheets[0])
            # st.info(f"üìã –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –ø–µ—Ä—à–∏–π –ª–∏—Å—Ç –¥–ª—è –∑–≤—ñ—Ç—ñ–≤: '{available_sheets[0]}'")
        
        # –í–∏—Ç—è–≥—É—î–º–æ –Ω–∞–∑–≤–∏
        lakes_names = []
        reports_names = []
        
        if lakes_df is not None and not lakes_df.empty:
            # –®—É–∫–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏ (–º–æ–∂–ª–∏–≤—ñ –≤–∞—Ä—ñ–∞–Ω—Ç–∏)
            name_columns = ['LakeHouse', 'name', 'Name', '–Ω–∞–∑–≤–∞', '–ù–∞–∑–≤–∞', 'lake_name', 'Lake Name', 'Lakehouse']
            name_col = None
            for col in name_columns:
                if col in lakes_df.columns:
                    name_col = col
                    break
            
            if name_col:
                lakes_names = list(lakes_df[name_col].dropna())
            else:
                # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏, –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –ø–µ—Ä—à—É –∫–æ–ª–æ–Ω–∫—É
                lakes_names = list(lakes_df.iloc[:, 0].dropna())
        
        if reports_df is not None and not reports_df.empty:
            name_columns = ['name', 'Name', '–Ω–∞–∑–≤–∞', '–ù–∞–∑–≤–∞', 'report_name', 'Report Name']
            name_col = None
            for col in name_columns:
                if col in reports_df.columns:
                    name_col = col
                    break
            
            if name_col:
                reports_names = list(reports_df[name_col].dropna())
            else:
                reports_names = list(reports_df.iloc[:, 0].dropna())
        
        return lakes_names, reports_names, lakes_df, reports_df
        
    except Exception as ex:
        st.error(f"‚ö†Ô∏è –ù–µ –≤–¥–∞–ª–æ—Å—è –∑—á–∏—Ç–∞—Ç–∏ —Ñ–∞–π–ª {excel_path}: {ex}")
        st.error(f"–î–µ—Ç–∞–ª—ñ –ø–æ–º–∏–ª–∫–∏: {str(ex)}")
        return [], [], None, None

# ======= –§—É–Ω–∫—Ü—ñ—ó –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –ª–µ–π–∫—ñ–≤ =========
@st.cache_data(ttl=300)
def analyze_lakes_data(lakes_df):
    """
    –ê–Ω–∞–ª—ñ–∑—É—î –¥–∞–Ω—ñ –ª–µ–π–∫—ñ–≤ —Ç–∞ –ø–æ–≤–µ—Ä—Ç–∞—î —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
    """
    if lakes_df is None or lakes_df.empty:
        return None
    
    analysis = {
        'total_lakes': len(lakes_df),
        'columns': list(lakes_df.columns),
        'data_types': lakes_df.dtypes.to_dict(),
        'missing_data': lakes_df.isnull().sum().to_dict(),
        'unique_values': {}
    }
    
    # –ê–Ω–∞–ª—ñ–∑ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å –¥–ª—è –∫–æ–∂–Ω–æ—ó –∫–æ–ª–æ–Ω–∫–∏
    for col in lakes_df.columns:
        if lakes_df[col].dtype == 'object':  # –¢–µ–∫—Å—Ç–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏
            analysis['unique_values'][col] = lakes_df[col].value_counts().to_dict()
    
    return analysis

def display_image_from_path(image_path, caption=None, width=None):
    """
    –í—ñ–¥–æ–±—Ä–∞–∂–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ —Ñ–∞–π–ª–æ–≤–æ–≥–æ —à–ª—è—Ö—É
    """
    try:
        if os.path.exists(image_path):
            image = Image.open(image_path)
            st.image(image, caption=caption, width=width)
        else:
            st.warning(f"‚ö†Ô∏è –ó–æ–±—Ä–∞–∂–µ–Ω–Ω—è –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {image_path}")
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {e}")

def display_image_from_base64(base64_string, caption=None, width=None):
    """
    –í—ñ–¥–æ–±—Ä–∞–∂–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –∑ base64 —Ä—è–¥–∫–∞
    """
    try:
        # –î–µ–∫–æ–¥—É—î–º–æ base64
        image_data = base64.b64decode(base64_string)
        st.image(image_data, caption=caption, width=width)
    except Exception as e:
        st.error(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –¥–µ–∫–æ–¥—É–≤–∞–Ω–Ω—ñ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è: {e}")

def process_text_with_images(text):
    """
    –û–±—Ä–æ–±–ª—è—î —Ç–µ–∫—Å—Ç —Ç–∞ –≤—ñ–¥–æ–±—Ä–∞–∂–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è, —è–∫—â–æ –∑–Ω–∞–π–¥–µ–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –Ω–∏—Ö
    """
    if not text:
        return text
    
    # –®—É–∫–∞—î–º–æ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è –≤ —Ç–µ–∫—Å—Ç—ñ
    import re
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω –¥–ª—è –ø–æ—à—É–∫—É –ø–æ—Å–∏–ª–∞–Ω—å –Ω–∞ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
    image_pattern = r'\[IMAGE:(.*?)\]'
    matches = re.findall(image_pattern, text)
    
    if matches:
        # –†–æ–∑–¥—ñ–ª—è—î–º–æ —Ç–µ–∫—Å—Ç –Ω–∞ —á–∞—Å—Ç–∏–Ω–∏
        parts = re.split(image_pattern, text)
        
        for i, part in enumerate(parts):
            if i % 2 == 0:  # –¢–µ–∫—Å—Ç
                if part.strip():
                    st.markdown(part)
            else:  # –®–ª—è—Ö –¥–æ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è
                image_path = part.strip()
                display_image_from_path(image_path, width=600)
    else:
        # –Ø–∫—â–æ –Ω–µ–º–∞—î –∑–æ–±—Ä–∞–∂–µ–Ω—å, –ø—Ä–æ—Å—Ç–æ –ø–æ–∫–∞–∑—É—î–º–æ —Ç–µ–∫—Å—Ç
        st.markdown(text)

def create_lakes_visualization(lakes_df):
    """
    –°—Ç–≤–æ—Ä—é—î –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –¥–ª—è –¥–∞–Ω–∏—Ö –ª–µ–π–∫—ñ–≤
    """
    if lakes_df is None or lakes_df.empty:
        return None
    
    visualizations = {}
    
    # 1. –°—Ç–∞—Ç—É—Å –ª–µ–π–∫—ñ–≤ (—è–∫—â–æ —î –∫–æ–ª–æ–Ω–∫–∞ status)
    if 'status' in lakes_df.columns:
        status_counts = lakes_df['status'].value_counts()
        fig_status = px.pie(
            values=status_counts.values, 
            names=status_counts.index,
            title="üìä –†–æ–∑–ø–æ–¥—ñ–ª —Å—Ç–∞—Ç—É—Å—ñ–≤ –ª–µ–π–∫—ñ–≤",
            color_discrete_sequence=px.colors.qualitative.Set3
        )
        visualizations['status_pie'] = fig_status
    
    # 2. –ß–∞—Å—Ç–æ—Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω—å (—è–∫—â–æ —î –∫–æ–ª–æ–Ω–∫–∞ update_freq)
    if 'update_freq' in lakes_df.columns:
        freq_counts = lakes_df['update_freq'].value_counts()
        fig_freq = px.bar(
            x=freq_counts.index, 
            y=freq_counts.values,
            title="‚è∞ –ß–∞—Å—Ç–æ—Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω—å –ª–µ–π–∫—ñ–≤",
            labels={'x': '–ß–∞—Å—Ç–æ—Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è', 'y': '–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ª–µ–π–∫—ñ–≤'},
            color=freq_counts.values,
            color_continuous_scale='Blues'
        )
        fig_freq.update_layout(xaxis_tickangle=-45)
        visualizations['frequency_bar'] = fig_freq
    
    # 3. Workspace —Ä–æ–∑–ø–æ–¥—ñ–ª (—è–∫—â–æ —î –∫–æ–ª–æ–Ω–∫–∞ workspace)
    if 'workspace' in lakes_df.columns:
        workspace_counts = lakes_df['workspace'].value_counts()
        fig_workspace = px.treemap(
            names=workspace_counts.index,
            parents=[''] * len(workspace_counts),
            values=workspace_counts.values,
            title="üè¢ –†–æ–∑–ø–æ–¥—ñ–ª –ª–µ–π–∫—ñ–≤ –ø–æ workspace"
        )
        visualizations['workspace_treemap'] = fig_workspace
    
    return visualizations

def create_lake_details_card(lake_row):
    """
    –°—Ç–≤–æ—Ä—é—î –¥–µ—Ç–∞–ª—å–Ω—É –∫–∞—Ä—Ç–∫—É –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ª–µ–π–∫–∞
    """
    if lake_row is None or lake_row.empty:
        return "–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –ø—Ä–æ –ª–µ–π–∫"
    
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –Ω–∞–∑–≤—É –ª–µ–π–∫–∞
    lake_name = lake_row.get('name', lake_row.get('Name', lake_row.get('–Ω–∞–∑–≤–∞', '–ù–µ–≤—ñ–¥–æ–º–∏–π –ª–µ–π–∫')))
    
    # –°—Ç–≤–æ—Ä—é—î–º–æ HTML –∫–∞—Ä—Ç–∫—É –∑ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—î—é
    card_html = f"""
    <div style="
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 20px;
        border-radius: 10px;
        color: white;
        margin: 10px 0;
        box-shadow: 0 4px 6px rgba(0, 0, 0, 0.1);
    ">
        <h3 style="margin: 0 0 15px 0; color: white;">üèûÔ∏è {lake_name}</h3>
    """
    
    # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –∑ —É—Å—ñ—Ö –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –∫–æ–ª–æ–Ω–æ–∫
    for col in lake_row.index:
        if pd.notna(lake_row[col]) and col.lower() not in ['name', '–Ω–∞–∑–≤–∞']:
            value = lake_row[col]
            # –ü–µ—Ä–µ–∫–ª–∞–¥–∞—î–º–æ –Ω–∞–∑–≤–∏ –∫–æ–ª–æ–Ω–æ–∫ –Ω–∞ —É–∫—Ä–∞—ó–Ω—Å—å–∫—É –¥–ª—è –∫—Ä–∞—â–æ–≥–æ —Ä–æ–∑—É–º—ñ–Ω–Ω—è
            col_translations = {
                'workspace': '–†–æ–±–æ—á–∏–π –ø—Ä–æ—Å—Ç—ñ—Ä',
                'update_freq': '–ß–∞—Å—Ç–æ—Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è',
                'last_update': '–û—Å—Ç–∞–Ω–Ω—î –æ–Ω–æ–≤–ª–µ–Ω–Ω—è',
                'status': '–°—Ç–∞—Ç—É—Å',
                'owner': '–í–ª–∞—Å–Ω–∏–∫',
                'description': '–û–ø–∏—Å',
                'size': '–†–æ–∑–º—ñ—Ä',
                'location': '–†–æ–∑—Ç–∞—à—É–≤–∞–Ω–Ω—è',
                'components': '–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏',
                'tables': '–¢–∞–±–ª–∏—Ü—ñ',
                'views': '–ü—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–Ω—è'
            }
            
            display_name = col_translations.get(col.lower(), col)
            card_html += f"""
            <div style="margin: 8px 0;">
                <strong>{display_name}:</strong> {value}
            </div>
            """
    
    card_html += "</div>"
    return card_html

# –î–ï–ú–û-–§–ê–ô–õ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó —è–∫—â–æ –π–æ–≥–æ –Ω–µ —ñ—Å–Ω—É—î (—Ç—ñ–ª—å–∫–∏ –ø–µ—Ä—à–∏–π –∑–∞–ø—É—Å–∫):
def create_default_config_file(path):
    lakes_df = pd.DataFrame({
        "name": ["Sales_Lake", "Inventory_Lake", "HR_Lake", "Finance_Lake"],
        "workspace": ["Sales_Analytics", "Inventory_Analytics", "HR_Analytics", "Finance_Analytics"],
        "update_freq": ["–©–æ–¥–Ω—è 06:00", "–ö–æ–∂–Ω—ñ 4 –≥–æ–¥–∏–Ω–∏", "–©–æ–¥–Ω—è 08:00", "–©–æ—Ç–∏–∂–Ω—è"],
        "last_update": ["08.10.2025 06:15", "08.10.2025 12:00", "08.10.2025 08:10", "07.10.2025"],
        "status": ["‚úÖ OK", "‚úÖ OK", "‚úÖ OK", "‚ö†Ô∏è –ó–∞—Ç—Ä–∏–º–∫–∞"]
    })
    reports_df = pd.DataFrame({
        "name": ["Sales Dashboard", "Inventory Report", "HR Analytics", "Financial Overview"],
        "workspace": ["Sales_Analytics", "Inventory_Analytics", "HR_Analytics", "Finance_Analytics"],
        "owner": ["–ú–∞—Ä–∫–µ—Ç–∏–Ω–≥", "–õ–æ–≥—ñ—Å—Ç–∏–∫–∞", "HR", "–§—ñ–Ω–∞–Ω—Å–∏"],
        "update_freq": ["–©–æ–¥–Ω—è", "–©–æ–¥–Ω—è", "–©–æ—Ç–∏–∂–Ω—è", "–©–æ–º—ñ—Å—è—Ü—è"],
        "lake": ["Sales_Lake", "Inventory_Lake", "HR_Lake", "Finance_Lake"],
        "status": ["‚úÖ OK", "‚úÖ OK", "‚úÖ OK", "‚ö†Ô∏è –ü–æ—Ç—Ä–µ–±—É—î —É–≤–∞–≥–∏"]
    })
    with pd.ExcelWriter(path) as writer:
        lakes_df.to_excel(writer, index=False, sheet_name="lakes")
        reports_df.to_excel(writer, index=False, sheet_name="reports")

if not os.path.exists(EXCEL_FILE_PATH):
    create_default_config_file(EXCEL_FILE_PATH)

# ==== STREAMLIT UI ====

st.set_page_config(
    page_title="–ë–∞–∑–∞ –∑–Ω–∞–Ω—å - –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –ø–æ —Ä–æ–±–æ—Ç—ñ",
    page_icon="üìö",
    layout="wide"
)

st.title("üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω—å: –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –ø–æ –æ–Ω–æ–≤–ª–µ–Ω–Ω—é –∑–≤—ñ—Ç—ñ–≤ —Ç–∞ –ª–µ–π–∫—ñ–≤")
st.markdown("*–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è –¥–ª—è –∫–æ–º–∞–Ω–¥–∏ Data Engineering*")
st.markdown("---")

st.sidebar.title("üóÇÔ∏è –ù–∞–≤—ñ–≥–∞—Ü—ñ—è")
st.sidebar.markdown("### –û–±–µ—Ä—ñ—Ç—å —Ä–æ–∑–¥—ñ–ª:")

section = st.sidebar.radio(
    "",
    ["üè† –ì–æ–ª–æ–≤–Ω–∞", 
     "üíß –û–Ω–æ–≤–ª–µ–Ω–Ω—è Data Lakes", 
     "üìä –û–Ω–æ–≤–ª–µ–Ω–Ω—è Power BI –∑–≤—ñ—Ç—ñ–≤",
     "üîå –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª",
     "üÜò Troubleshooting",
     "üìû –ö–æ–Ω—Ç–∞–∫—Ç–∏ —Ç–∞ —Ä–µ—Å—É—Ä—Å–∏"]
)

st.sidebar.markdown("---")
st.sidebar.info(f"üìÖ –û—Å—Ç–∞–Ω–Ω—î –æ–Ω–æ–≤–ª–µ–Ω–Ω—è:\n{datetime.now().strftime('%d.%m.%Y')}")

# –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –¥–æ—Å—Ç—É–ø –¥–ª—è –∫–æ–ª–µ–≥
st.sidebar.markdown("---")
st.sidebar.markdown("üåê **–î–æ—Å—Ç—É–ø –¥–ª—è –∫–æ–ª–µ–≥:**")
st.sidebar.markdown("–î–ª—è –¥–æ—Å—Ç—É–ø—É –∑ —ñ–Ω—à–∏—Ö –∫–æ–º–ø'—é—Ç–µ—Ä—ñ–≤:")
st.sidebar.markdown("1. –ó–∞–ø—É—Å—Ç—ñ—Ç—å –∑ –∫–æ–º–∞–Ω–¥–æ—é:")
st.sidebar.code("streamlit run \"C:\\Users\\oleksandra.filatova\\OneDrive - PHARMACEUTICAL COMPANY DARNYTSIA\\–ë–ª–æ–∫–Ω–æ—Ç–∏\\Streamlit\\knowledge_transfer.py\" --server.address 192.168.1.105")
st.sidebar.markdown("2. –î–∞–π—Ç–µ –∫–æ–ª–µ–≥–∞–º –ø–æ—Å–∏–ª–∞–Ω–Ω—è:")
st.sidebar.code("http://192.168.1.105:8501")

# === –î–ò–ù–ê–ú–ò–ß–ï–°–ö–ò–ô –ó–ê–ü–†–û–° —Ç–∞–±–ª–∏—Ü—ã Excel –¥–ª—è Lakes & reports ===
# –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —Ñ–∞–π–ª —ñ—Å–Ω—É—î –ª–æ–∫–∞–ª—å–Ω–æ
if os.path.exists(EXCEL_FILE_PATH):
    lakes, reports, lakes_table, reports_table = load_lakes_and_reports(EXCEL_FILE_PATH)
else:
    # –Ø–∫—â–æ —Ñ–∞–π–ª –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ, –ø—Ä–æ–ø–æ–Ω—É—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏
    st.warning("‚ö†Ô∏è –§–∞–π–ª LakeHouse.xlsx –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ. –ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª:")
    uploaded_file = st.file_uploader("–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ Excel —Ñ–∞–π–ª", type=['xlsx', 'xls'])
    
    if uploaded_file is not None:
        # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–∏–π —Ñ–∞–π–ª
        with open("LakeHouse.xlsx", "wb") as f:
            f.write(uploaded_file.getbuffer())
        st.success("‚úÖ –§–∞–π–ª –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ! –û–Ω–æ–≤–ª—é—î–º–æ –¥–∞–Ω—ñ...")
        lakes, reports, lakes_table, reports_table = load_lakes_and_reports("LakeHouse.xlsx")
    else:
        # –ü–æ–∫–∞–∑—É—î–º–æ –∑–∞–≥–ª—É—à–∫—É
        lakes, reports, lakes_table, reports_table = [], [], None, None
        st.info("üëÜ –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ Excel —Ñ–∞–π–ª –¥–ª—è –ø–æ—á–∞—Ç–∫—É —Ä–æ–±–æ—Ç–∏")

# ==================== –ì–û–õ–û–í–ù–ê –°–¢–û–†–Ü–ù–ö–ê ====================
if section == "üè† –ì–æ–ª–æ–≤–Ω–∞":
    st.header("–í—ñ—Ç–∞—î–º–æ! üëã")
    st.markdown("""
    –¶—è –±–∞–∑–∞ –∑–Ω–∞–Ω—å –º—ñ—Å—Ç–∏—Ç—å –≤—Å—é –Ω–µ–æ–±—Ö—ñ–¥–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –¥–ª—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ —Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è 
    –Ω–∞—à–∏—Ö Data Lakes —Ç–∞ Power BI –∑–≤—ñ—Ç—ñ–≤.

    **‚ö°Ô∏è –¢–µ–ø–µ—Ä —Å–ø–∏—Å–æ–∫ –ª–µ–π–∫—ñ–≤ —ñ –∑–≤—ñ—Ç—ñ–≤ –∑—á–∏—Ç—É—î—Ç—å—Å—è –∑ —Ç–∞–±–ª–∏—Ü—ñ Excel**  
    –ú–æ–∂–Ω–∞ –ª–µ–≥–∫–æ –∫–æ—Ä–∏–≥—É–≤–∞—Ç–∏ —Å–∫–ª–∞–¥ –±–µ–∑ –∑–º—ñ–Ω–∏ –∫–æ–¥—É!
    
    **Excel —Ñ–∞–π–ª:** `{}`  
    """.format(EXCEL_FILE_PATH))
    col1, col2 = st.columns(2)
    with col1:
        st.info("""
        **üíß Data Lakes**
        - –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –ø–æ –æ–Ω–æ–≤–ª–µ–Ω–Ω—é
        - –ì—Ä–∞—Ñ—ñ–∫ –æ–Ω–æ–≤–ª–µ–Ω—å
        - –°–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –ª–µ–π–∫—ñ–≤
        - Troubleshooting
        """)
        st.success("""
        **üìä Power BI –ó–≤—ñ—Ç–∏**
        - –ü–æ–∫—Ä–æ–∫–æ–≤—ñ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó
        - –°–ø–∏—Å–æ–∫ –∑–≤—ñ—Ç—ñ–≤
        - –í–ª–∞—Å–Ω–∏–∫–∏ –∑–≤—ñ—Ç—ñ–≤
        - –ß–∞—Å—Ç—ñ –ø–æ–º–∏–ª–∫–∏
        """)
    with col2:
        st.warning("""
        **üîå –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª**
        - Connection strings
        - –û–±–ª—ñ–∫–æ–≤—ñ –∑–∞–ø–∏—Å–∏
        - –ü—Ä–∞–≤–∞ –¥–æ—Å—Ç—É–ø—É
        - API endpoints
        """)
        st.error("""
        **üÜò –©–æ —Ä–æ–±–∏—Ç–∏ —è–∫—â–æ...**
        - –ó–≤—ñ—Ç –Ω–µ –æ–Ω–æ–≤–ª—é—î—Ç—å—Å—è
        - –ü–æ–º–∏–ª–∫–∏ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è
        - –ü—Ä–æ–±–ª–µ–º–∏ –∑ –¥–∞–Ω–∏–º–∏
        - –ï–∫—Å—Ç—Ä–µ–Ω—ñ –∫–æ–Ω—Ç–∞–∫—Ç–∏
        """)
    st.markdown("---")
    st.markdown("### üöÄ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç")
    st.markdown("–û–±–µ—Ä—ñ—Ç—å —Ä–æ–∑–¥—ñ–ª –∑ –º–µ–Ω—é –∑–ª—ñ–≤–∞ üëà")

# ==================== –û–ù–û–í–õ–ï–ù–ù–Ø DATA LAKES ====================
elif section == "üíß –û–Ω–æ–≤–ª–µ–Ω–Ω—è Data Lakes":
    st.header("üíß –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –ø–æ –æ–Ω–æ–≤–ª–µ–Ω–Ω—é Data Lakes")
    
    # –ê–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö –±—É–¥–µ –ø–æ–∫–∞–∑–∞–Ω–æ –ø—ñ—Å–ª—è –≤–∏–±–æ—Ä—É –ª–µ–π–∫–∞
    
    # –û—Ç—Ä–∏–º—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –Ω–∞–∑–≤–∏ –ª–µ–π–∫—ñ–≤ (–±–µ–∑ –¥—É–±–ª—é–≤–∞–Ω–Ω—è)
    unique_lakes = []
    if lakes_table is not None and not lakes_table.empty:
        # –®—É–∫–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏ –ª–µ–π–∫—ñ–≤
        name_columns = ['LakeHouse', 'name', 'Name', '–Ω–∞–∑–≤–∞', '–ù–∞–∑–≤–∞', 'lake_name', 'Lake Name']
        name_col = None
        for col in name_columns:
            if col in lakes_table.columns:
                name_col = col
                break
        
        if name_col:
            unique_lakes = lakes_table[name_col].dropna().unique().tolist()
        else:
            # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏, –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –ø–µ—Ä—à—É –∫–æ–ª–æ–Ω–∫—É
            unique_lakes = lakes_table.iloc[:, 0].dropna().unique().tolist()
    
    lake_select_options = ["–í—Å—ñ –ª–µ–π–∫–∏", "üìä –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è"]
    if unique_lakes:
        lake_select_options += unique_lakes
    
    lake_name = st.selectbox(
        "–û–±–µ—Ä—ñ—Ç—å Data Lake:",
        lake_select_options
    )
    
    if lake_name == "–í—Å—ñ –ª–µ–π–∫–∏":
        st.info("üëà –û–±–µ—Ä—ñ—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –ª–µ–π–∫ –∑—ñ —Å–ø–∏—Å–∫—É –≤–∏—â–µ")
        
        # –ü–æ–∫–∞–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –ª–µ–π–∫–∏ –∑ –∫–æ–ª–æ–Ω–∫–∏ LakeHouse
        if lakes_table is not None and not lakes_table.empty:
            # –û—Ç—Ä–∏–º—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –∑ –∫–æ–ª–æ–Ω–∫–∏ LakeHouse
            unique_lakes = lakes_table['LakeHouse'].dropna().unique()
            
            # –ü–æ–∫–∞–∑—É—î–º–æ –º–µ—Ç—Ä–∏–∫—É —Ç—ñ–ª—å–∫–∏ –¥–ª—è –∫—ñ–ª—å–∫–æ—Å—Ç—ñ —É–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ª–µ–π–∫—ñ–≤
            col1, col2, col3, col4 = st.columns(4)
            with col1:
                st.metric("üèûÔ∏è –£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ª–µ–π–∫—ñ–≤", len(unique_lakes))
            with col2:
                st.metric("", "")  # –ü–æ—Ä–æ–∂–Ω—è –∫–∞—Ä—Ç–∫–∞
            with col3:
                st.metric("", "")  # –ü–æ—Ä–æ–∂–Ω—è –∫–∞—Ä—Ç–∫–∞
            with col4:
                st.metric("", "")  # –ü–æ—Ä–æ–∂–Ω—è –∫–∞—Ä—Ç–∫–∞
            
            st.subheader("üìã –°–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö Data Lakes")
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–∞–±–ª–∏—Ü—é —Ç—ñ–ª—å–∫–∏ –∑ 2 –∫–æ–ª–æ–Ω–∫–∞–º–∏
            if 'LakeHouse' in lakes_table.columns and '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫' in lakes_table.columns:
                # –ì—Ä—É–ø—É—î–º–æ –ø–æ LakeHouse —Ç–∞ –±–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π –∑–∞–ø–∏—Å –¥–ª—è –∫–æ–∂–Ω–æ—ó –≥—Ä—É–ø–∏
                summary_table = lakes_table.groupby('LakeHouse').first().reset_index()
                
                # –ü–æ–∫–∞–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ –ø–æ—Ç—Ä—ñ–±–Ω—ñ –∫–æ–ª–æ–Ω–∫–∏
                display_columns = ['LakeHouse', '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫']
                summary_display = summary_table[display_columns]
                
                st.dataframe(
                    summary_display, 
                    use_container_width=True,
                    hide_index=True
                )
                
                # –î–æ–¥–∞—î–º–æ –∫–Ω–æ–ø–∫—É –¥–ª—è –µ–∫—Å–ø–æ—Ä—Ç—É
                csv = summary_display.to_csv(index=False)
                st.download_button(
                    label="üì• –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ CSV",
                    data=csv,
                    file_name=f"lakes_summary_{datetime.now().strftime('%Y%m%d')}.csv",
                    mime="text/csv"
                )
            else:
                st.warning("‚ö†Ô∏è –ù–µ –∑–Ω–∞–π–¥–µ–Ω–æ –∫–æ–ª–æ–Ω–∫–∏ 'LakeHouse' –∞–±–æ '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫'")
        else:
            st.warning("–°–ø–∏—Å–æ–∫ –ª–µ–π–∫—ñ–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π —É —Ñ–∞–π–ª—ñ Excel!")
    
    elif lake_name == "üìä –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è":
        st.subheader("üìä –ê–Ω–∞–ª—ñ—Ç–∏–∫–∞ —Ç–∞ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –ª–µ–π–∫—ñ–≤")
        
        if lakes_table is not None and not lakes_table.empty:
            # –°—Ç–≤–æ—Ä—é—î–º–æ –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
            visualizations = create_lakes_visualization(lakes_table)
            
            if visualizations:
                # –ü–æ–∫–∞–∑—É—î–º–æ –≥—Ä–∞—Ñ—ñ–∫–∏ –≤ –∫–æ–ª–æ–Ω–∫–∞—Ö
                if 'status_pie' in visualizations:
                    st.plotly_chart(visualizations['status_pie'], use_container_width=True)
                
                col1, col2 = st.columns(2)
                with col1:
                    if 'frequency_bar' in visualizations:
                        st.plotly_chart(visualizations['frequency_bar'], use_container_width=True)
                with col2:
                    if 'workspace_treemap' in visualizations:
                        st.plotly_chart(visualizations['workspace_treemap'], use_container_width=True)
                
                # –î–æ–¥–∞—î–º–æ –¥–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
                st.subheader("üîç –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑")
                analysis = analyze_lakes_data(lakes_table)
                
                with st.expander("üìà –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∫–æ–ª–æ–Ω–∫–∞—Ö"):
                    for col in analysis['columns']:
                        missing_count = analysis['missing_data'][col]
                        total_count = analysis['total_lakes']
                        completeness = ((total_count - missing_count) / total_count) * 100
                        
                        st.write(f"**{col}:** {completeness:.1f}% –∑–∞–ø–æ–≤–Ω–µ–Ω–æ ({total_count - missing_count}/{total_count})")
                
                with st.expander("üìä –£–Ω—ñ–∫–∞–ª—å–Ω—ñ –∑–Ω–∞—á–µ–Ω–Ω—è"):
                    for col, values in analysis['unique_values'].items():
                        st.write(f"**{col}:**")
                        for value, count in values.items():
                            st.write(f"  - {value}: {count}")
            else:
                st.info("–ù–µ–¥–æ—Å—Ç–∞—Ç–Ω—å–æ –¥–∞–Ω–∏—Ö –¥–ª—è —Å—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ–π")
        else:
            st.warning("–ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É")
    
    else:
        # –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ lake
        if lakes_table is not None and not lakes_table.empty:
            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –¥–∞–Ω—ñ –¥–ª—è –≤–∏–±—Ä–∞–Ω–æ–≥–æ –ª–µ–π–∫–∞
            lake_data = None
            
            # –®—É–∫–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É –∑ –Ω–∞–∑–≤–∞–º–∏ –ª–µ–π–∫—ñ–≤
            name_columns = ['LakeHouse', 'name', 'Name', '–Ω–∞–∑–≤–∞', '–ù–∞–∑–≤–∞', 'lake_name', 'Lake Name', 'Lakehouse']
            name_col = None
            for col in name_columns:
                if col in lakes_table.columns:
                    if lake_name in lakes_table[col].values:
                        name_col = col
                        lake_data = lakes_table[lakes_table[col] == lake_name]
                        break
            
            # –Ø–∫—â–æ –Ω–µ –∑–Ω–∞–π—à–ª–∏ –∑–∞ –Ω–∞–∑–≤–æ—é, –∞–ª–µ —î —Ç—ñ–ª—å–∫–∏ –æ–¥–∏–Ω —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π –ª–µ–π–∫ - –≤–∏–∫–æ—Ä–∏—Å—Ç–∞—î–º–æ –≤—Å—ñ –¥–∞–Ω—ñ
            if lake_data is None or lake_data.empty:
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —î —Ç—ñ–ª—å–∫–∏ –æ–¥–∏–Ω —É–Ω—ñ–∫–∞–ª—å–Ω–∏–π –ª–µ–π–∫
                unique_lakes = []
                for col in name_columns:
                    if col in lakes_table.columns:
                        unique_lakes = lakes_table[col].dropna().unique().tolist()
                        if len(unique_lakes) == 1:
                            lake_data = lakes_table
                            st.info(f"üí° –í–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ —î–¥–∏–Ω–∏–π –ª–µ–π–∫: {unique_lakes[0]}")
                            break
            
            if lake_data is not None and not lake_data.empty:
                st.success(f"üèûÔ∏è –í–∏–±—Ä–∞–Ω–æ –ª–µ–π–∫: **{lake_name}**")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –∞–Ω–∞–ª—ñ–∑ –¥–∞–Ω–∏—Ö –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –ª–µ–π–∫–∞
                if lakes_table is not None and not lakes_table.empty:
                    # –†–∞—Ö—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –ª–µ–π–∫–∏ –∑ –∫–æ–ª–æ–Ω–∫–∏ LakeHouse
                    unique_lakes_count = lakes_table['LakeHouse'].nunique()
                    
                    # –†–∞—Ö—É—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –µ–ª–µ–º–µ–Ω—Ç–∏ –∑ –∫–æ–ª–æ–Ω–∫–∏ Element
                    unique_elements_count = lakes_table['Element'].nunique() if 'Element' in lakes_table.columns else 0
                    
                    col1, col2 = st.columns(2)
                    with col1:
                        st.metric("üèûÔ∏è –í—Å—å–æ–≥–æ –ª–µ–π–∫—ñ–≤", unique_lakes_count)
                    with col2:
                        st.metric("üß© –ö—ñ–ª—å–∫—ñ—Å—Ç—å –µ–ª–µ–º–µ–Ω—Ç—ñ–≤", unique_elements_count)
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –∑–∞–≥–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ª–µ–π–∫ –∑ –∫–æ–ª–æ–Ω–∫–∏ "–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫"
                st.subheader("‚ÑπÔ∏è –ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫")
                if '–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫' in lake_data.columns and pd.notna(lake_data['–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫'].iloc[0]):
                    st.info(lake_data['–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫'].iloc[0])
                else:
                    st.info("–ó–∞–≥–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –ª–µ–π–∫ –Ω–µ –Ω–∞–¥–∞–Ω–∞")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –ª–µ–π–∫–∞ —Ç—ñ–ª—å–∫–∏ —è–∫—â–æ —î –∫–æ–ª–æ–Ω–∫–∞ Folder
                if 'Folder' in lake_data.columns:
                    st.subheader("üìÅ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ª–µ–π–∫–∞")
                    
                    # –ü–æ–∫–∞–∑—É—î–º–æ —Ç—ñ–ª—å–∫–∏ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –ø–∞–ø–∫–∏
                    unique_folders = lake_data['Folder'].dropna().unique().tolist()
                    
                    if unique_folders:
                        st.write("**–î–æ—Å—Ç—É–ø–Ω—ñ –ø–∞–ø–∫–∏:**")
                        
                        # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–ª—ñ–∫–∞–±–µ–ª—å–Ω—ñ –∫–Ω–æ–ø–∫–∏ –¥–ª—è –ø–∞–ø–æ–∫
                        cols = st.columns(min(len(unique_folders), 3))  # –ú–∞–∫—Å–∏–º—É–º 3 –∫–æ–ª–æ–Ω–∫–∏
                        selected_folder = None
                        
                        for i, folder in enumerate(unique_folders):
                            col_idx = i % 3
                            with cols[col_idx]:
                                if st.button(f"üìÇ {folder}", key=f"folder_{folder}", use_container_width=True):
                                    selected_folder = folder
                        
                        # –ü–æ–∫–∞–∑—É—î–º–æ –¥–µ—Ç–∞–ª—ñ –≤–∏–±—Ä–∞–Ω–æ—ó –ø–∞–ø–∫–∏
                        if selected_folder:
                            st.success(f"üìÇ –í–∏–±—Ä–∞–Ω–æ –ø–∞–ø–∫—É: **{selected_folder}**")
                            
                            # –§—ñ–ª—å—Ç—Ä—É—î–º–æ –¥–∞–Ω—ñ –ø–æ –≤–∏–±—Ä–∞–Ω—ñ–π –ø–∞–ø—Ü—ñ
                            folder_data = lake_data[lake_data['Folder'] == selected_folder]
                            
                            # –ü–æ–∫–∞–∑—É—î–º–æ –µ–ª–µ–º–µ–Ω—Ç–∏ –ø–∞–ø–∫–∏ (—Ç—ñ–ª—å–∫–∏ —Å—Ç–æ–≤–ø—Ü—ñ –∑ 3 –ø–æ 8)
                            st.subheader("üß© –ï–ª–µ–º–µ–Ω—Ç–∏ –ø–∞–ø–∫–∏")
                            
                            # –í–∏–±–∏—Ä–∞—î–º–æ —Å—Ç–æ–≤–ø—Ü—ñ –∑ 3 –ø–æ 8 (—ñ–Ω–¥–µ–∫—Å–∏ 2-7), –∞–ª–µ –≤–∏–∫–ª—é—á–∞—î–º–æ URL
                            display_columns = folder_data.columns[2:9]
                            # –í–∏–∫–ª—é—á–∞—î–º–æ –∫–æ–ª–æ–Ω–∫—É URL –∑ –≤—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è, —è–∫—â–æ –≤–æ–Ω–∞ —î
                            if 'URL' in display_columns:
                                display_columns = [col for col in display_columns if col != 'URL']
                            
                            if 'Element' in display_columns:
                                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ, —á–∏ —î –∫–æ–ª–æ–Ω–∫–∞ URL
                                if 'URL' in folder_data.columns:
                                    # –°—Ç–≤–æ—Ä—é—î–º–æ –∫–æ–ø—ñ—é –¥–ª—è –º–æ–¥–∏—Ñ—ñ–∫–∞—Ü—ñ—ó
                                    elements_df_display = folder_data[display_columns].copy()
                                    
                                    # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–æ–≤–Ω–∏–∫ URL –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞ (–∑–∞ —ñ–Ω–¥–µ–∫—Å–æ–º)
                                    url_dict = {}
                                    for idx, row in folder_data.iterrows():
                                        url_value = row.get('URL', '')
                                        if pd.notna(url_value) and url_value.strip():
                                            url_dict[idx] = url_value.strip()
                                    
                                    # –ü–µ—Ä–µ—Ç–≤–æ—Ä—é—î–º–æ —Å—Ç–æ–≤–ø–µ—Ü—å 'Element' –Ω–∞ –∫–ª—ñ–∫–∞–±–µ–ª—å–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è
                                    def create_link(row_data):
                                        element_name = row_data['Element']
                                        row_idx = row_data.name  # –û—Ç—Ä–∏–º—É—î–º–æ —ñ–Ω–¥–µ–∫—Å —Ä—è–¥–∫–∞
                                        
                                        if row_idx in url_dict:
                                            url = url_dict[row_idx]
                                            return f'<a href="{url}" target="_blank" style="color: #1f77b4; text-decoration: underline;">{element_name}</a>'
                                        else:
                                            return element_name
                                    
                                    # –ó–∞—Å—Ç–æ—Å–æ–≤—É—î–º–æ —Ñ—É–Ω–∫—Ü—ñ—é –¥–æ –∫–æ–∂–Ω–æ–≥–æ —Ä—è–¥–∫–∞
                                    elements_df_display['Element'] = elements_df_display.apply(create_link, axis=1)
                                    
                                    # –ü–æ–∫–∞–∑—É—î–º–æ —Ç–∞–±–ª–∏—Ü—é –∑ HTML –ø–æ—Å–∏–ª–∞–Ω–Ω—è–º–∏
                                    st.markdown(elements_df_display.to_html(escape=False), unsafe_allow_html=True)
                                    
                                    # –î–æ–¥–∞—î–º–æ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –∫—ñ–ª—å–∫—ñ—Å—Ç—å –ø–æ—Å–∏–ª–∞–Ω—å
                                    active_links = len(url_dict)
                                    if active_links > 0:
                                        st.info(f"üîó {active_links} –∑ {len(folder_data)} –µ–ª–µ–º–µ–Ω—Ç—ñ–≤ –º–∞—é—Ç—å –∞–∫—Ç–∏–≤–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è")
                                else:
                                    # –Ø–∫—â–æ –Ω–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏ URL, –ø–æ–∫–∞–∑—É—î–º–æ –∑–≤–∏—á–∞–π–Ω—É —Ç–∞–±–ª–∏—Ü—é
                                    st.dataframe(folder_data[display_columns], use_container_width=True, hide_index=True)
                                    st.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'URL' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∫–∞–∑—É—î–º–æ –∑–≤–∏—á–∞–π–Ω—É —Ç–∞–±–ª–∏—Ü—é.")
                            else:
                                st.dataframe(folder_data[display_columns], use_container_width=True, hide_index=True)
                            
                            # –î–æ–¥–∞—î–º–æ —Å–µ–∫—Ü—ñ—é "–í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω"
                            st.subheader("üìù –í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω")
                            changes_col = '–í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω'
                            if changes_col in folder_data.columns and pd.notna(folder_data[changes_col].iloc[0]):
                                with st.expander("–ü–æ–∫–∞–∑–∞—Ç–∏ –¥–µ—Ç–∞–ª—ñ –∑–º—ñ–Ω", expanded=True):
                                    changes_text = folder_data[changes_col].iloc[0]
                                    # –û–±—Ä–æ–±–ª—è—î–º–æ —Ç–µ–∫—Å—Ç –∑ –º–æ–∂–ª–∏–≤–∏–º–∏ –∑–æ–±—Ä–∞–∂–µ–Ω–Ω—è–º–∏
                                    process_text_with_images(changes_text)
                            else:
                                st.info("–ù–µ–º–∞—î —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –≤–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω –¥–ª—è —Ü—ñ—î—ó –ø–∞–ø–∫–∏.")
                        else:
                            st.info("üëÜ –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å –Ω–∞ –ø–∞–ø–∫—É –≤–∏—â–µ, —â–æ–± –ø–æ–±–∞—á–∏—Ç–∏ —ó—ó –µ–ª–µ–º–µ–Ω—Ç–∏")
                    else:
                        st.warning("‚ö†Ô∏è –ü–∞–ø–∫–∏ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –¥–∞–Ω–∏—Ö")
                else:
                    # –Ø–∫—â–æ –Ω–µ–º–∞—î –∫–æ–ª–æ–Ω–∫–∏ Folder, –ø–æ–∫–∞–∑—É—î–º–æ –≤—Å—é —Ç–∞–±–ª–∏—Ü—é
                    st.warning("‚ö†Ô∏è –ö–æ–ª–æ–Ω–∫–∞ 'Folder' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞. –ü–æ–∫–∞–∑—É—î–º–æ –≤—Å—ñ –¥–∞–Ω—ñ:")
                    st.dataframe(lake_data, use_container_width=True, hide_index=True)
                
                # –°–µ–∫—Ü—ñ—è "–í–Ω–µ—Å–µ–Ω–Ω—è –∑–º—ñ–Ω" —Ç–µ–ø–µ—Ä –ø–æ–∫–∞–∑—É—î—Ç—å—Å—è —Ç—ñ–ª—å–∫–∏ –ø—ñ—Å–ª—è –≤–∏–±–æ—Ä—É –ø–∞–ø–∫–∏
            else:
                st.error(f"‚ùå –õ–µ–π–∫ '{lake_name}' –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö!")
                st.info("üí° –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —á–∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ –≤–∫–∞–∑–∞–Ω–∞ –Ω–∞–∑–≤–∞ –ª–µ–π–∫–∞")
                
                # –ü–æ–∫–∞–∑—É—î–º–æ –¥–æ—Å—Ç—É–ø–Ω—ñ –ª–µ–π–∫–∏ –¥–ª—è –¥–æ–≤—ñ–¥–∫–∏
                if unique_lakes:
                    st.subheader("üìã –î–æ—Å—Ç—É–ø–Ω—ñ –ª–µ–π–∫–∏:")
                    for lake in unique_lakes:
                        st.write(f"‚Ä¢ {lake}")
                else:
                    st.warning("‚ö†Ô∏è –ù–µ–º–∞—î –¥–æ—Å—Ç—É–ø–Ω–∏—Ö –ª–µ–π–∫—ñ–≤ –≤ –±–∞–∑—ñ –¥–∞–Ω–∏—Ö")
        else:
            st.warning("‚ö†Ô∏è –ù–µ–º–∞—î –¥–∞–Ω–∏—Ö –ø—Ä–æ –ª–µ–π–∫–∏")

# ==================== –û–ù–û–í–õ–ï–ù–ù–Ø POWER BI ====================
elif section == "üìä –û–Ω–æ–≤–ª–µ–Ω–Ω—è Power BI –∑–≤—ñ—Ç—ñ–≤":
    st.header("üìä –Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—ó –ø–æ –æ–Ω–æ–≤–ª–µ–Ω–Ω—é Power BI –∑–≤—ñ—Ç—ñ–≤")
    report_select_options = ["–í—Å—ñ –∑–≤—ñ—Ç–∏"]
    if reports:
        report_select_options += reports
    report_name = st.selectbox(
        "–û–±–µ—Ä—ñ—Ç—å –∑–≤—ñ—Ç:",
        report_select_options
    )
    if report_name == "–í—Å—ñ –∑–≤—ñ—Ç–∏":
        st.info("üëà –û–±–µ—Ä—ñ—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –∑–≤—ñ—Ç –∑—ñ —Å–ø–∏—Å–∫—É –≤–∏—â–µ")
        st.subheader("üìã –°–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –∑–≤—ñ—Ç—ñ–≤")
        if reports_table is not None and not reports_table.empty:
            st.dataframe(reports_table, use_container_width=True)
        else:
            st.warning("–°–ø–∏—Å–æ–∫ –∑–≤—ñ—Ç—ñ–≤ –ø–æ—Ä–æ–∂–Ω—ñ–π —É —Ñ–∞–π–ª—ñ Excel!")
    else:
        # –ü—ñ–¥—Ç—è–≥–Ω—É—Ç–∏ –º–∞–∫—Å–∏–º—É–º detail –ø–æ –∑–≤—ñ—Ç—É –∑ Excel
        if reports_table is not None and report_name in reports_table["name"].values:
            r_row = reports_table[reports_table["name"] == report_name].iloc[0]
            info_md = f"""
            **–ù–∞–∑–≤–∞ –∑–≤—ñ—Ç—É:** {r_row['name']}  
            **Workspace:** {r_row.get('workspace','')}  
            **–í–ª–∞—Å–Ω–∏–∫:** {r_row.get('owner','')}  
            **–ß–∞—Å—Ç–æ—Ç–∞ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è:** {r_row.get('update_freq','')}  
            **–î–∂–µ—Ä–µ–ª–æ –¥–∞–Ω–∏—Ö (–ª–µ–π–∫):** {r_row.get('lake', '')}
            **–°—Ç–∞—Ç—É—Å:** {r_row.get('status', '')}  
            """
        else:
            info_md = f"**–ù–∞–∑–≤–∞ –∑–≤—ñ—Ç—É:** {report_name}"
        st.success(f"–Ü–Ω—Å—Ç—Ä—É–∫—Ü—ñ—è –¥–ª—è: **{report_name}**")
        with st.expander("‚ÑπÔ∏è –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∑–≤—ñ—Ç", expanded=True):
            st.markdown(info_md)
        st.subheader("üìù –Ø–∫ –æ–Ω–æ–≤–∏—Ç–∏ –∑–≤—ñ—Ç")
        with st.expander("–ö—Ä–æ–∫ 1Ô∏è‚É£: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –¥–∞–Ω–∏—Ö –≤ Lakehouse", expanded=True):
            st.markdown("""
            –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —â–æ –¥–∞–Ω—ñ –≤ –ø–æ–≤'—è–∑–∞–Ω–æ–º—É Lakehouse –∞–∫—Ç—É–∞–ª—å–Ω—ñ, –ø–µ—Ä–µ–¥ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è–º –∑–≤—ñ—Ç—É.
            """)
            st.checkbox("‚úì –î–∞–Ω—ñ –≤ Lake –∞–∫—Ç—É–∞–ª—å–Ω—ñ", key=f"{report_name}_lake_data")
        with st.expander("–ö—Ä–æ–∫ 2Ô∏è‚É£: –û–Ω–æ–≤–ª–µ–Ω–Ω—è Dataset –≤ Power BI Service"):
            st.markdown("""
            –û–Ω–æ–≤—ñ—Ç—å dataset —É Power BI ‚Äî –≤—Ä—É—á–Ω—É –∞–±–æ —á–µ—Ä–µ–∑ plan/schedule.
            """)
            st.checkbox("‚úì Dataset –æ–Ω–æ–≤–ª–µ–Ω–æ", key=f"{report_name}_pbirefresh")
        with st.expander("–ö—Ä–æ–∫ 3Ô∏è‚É£: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∑–≤—ñ—Ç—É"):
            st.markdown("""
            –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –≥–æ–ª–æ–≤–Ω—ñ —Å—Ç–æ—Ä—ñ–Ω–∫–∏, —Ñ—ñ–ª—å—Ç—Ä–∏, –¥–∞—Ç–∏ —Ç–∞ –≤—ñ–∑—É–∞–ª–∏ –Ω–∞ –∫–æ—Ä–µ–∫—Ç–Ω—ñ—Å—Ç—å.
            """)
            st.checkbox("‚úì –ó–≤—ñ—Ç –ø—Ä–∞—Ü—é—î –∫–æ—Ä–µ–∫—Ç–Ω–æ", key=f"{report_name}_ok")
        st.success("‚úÖ –ì–æ—Ç–æ–≤–æ! –Ø–∫—â–æ –≤—Å—ñ —á–µ–∫–±–æ–∫—Å–∏ –≤—ñ–¥–º—ñ—á–µ–Ω—ñ - –∑–≤—ñ—Ç –æ–Ω–æ–≤–ª–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ")

# ==================== –ü–Ü–î–ö–õ–Æ–ß–ï–ù–ù–Ø –î–ñ–ï–†–ï–õ ====================
elif section == "üîå –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª":
    st.header("üîå –ü—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–∂–µ—Ä–µ–ª –¥–∞–Ω–∏—Ö")
    st.warning("‚ö†Ô∏è **–í–ê–ñ–õ–ò–í–û:** –í—Å—ñ –ø–∞—Ä–æ–ª—ñ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ Azure Key Vault. –ù—ñ–∫–æ–ª–∏ –Ω–µ –∑–∞–ø–∏—Å—É–π—Ç–µ —ó—Ö —É –≤—ñ–¥–∫—Ä–∏—Ç–æ–º—É –≤–∏–≥–ª—è–¥—ñ!")
    source_type = st.selectbox(
        "–û–±–µ—Ä—ñ—Ç—å —Ç–∏–ø –¥–∂–µ—Ä–µ–ª–∞:",
        ["–í—Å—ñ –¥–∂–µ—Ä–µ–ª–∞", "SQL Server", "OData (1–°)", "REST API", "SharePoint", "Excel —Ñ–∞–π–ª–∏"]
    )
    if source_type == "SQL Server":
        st.subheader("üóÑÔ∏è SQL Server –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è")
        with st.expander("üìç Production SQL Server", expanded=True):
            st.markdown("""
            ### Connection String:
            ```
            Server=sql-prod-server.database.windows.net;
            Database=Production_DB;
            Authentication=Active Directory Integrated;
            ```
            ### –û–±–ª—ñ–∫–æ–≤—ñ –¥–∞–Ω—ñ:
            - **Username:** –ó–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤ Key Vault (`sql-prod-username`)
            - **Password:** –ó–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤ Key Vault (`sql-prod-password`)
            ### –Ø–∫ –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –∑ Fabric:
            1. Data Factory ‚Üí New Connection
            2. –û–±–µ—Ä—ñ—Ç—å "SQL Server"
            3. –í–≤–µ–¥—ñ—Ç—å server name
            4. Authentication method: SQL Authentication
            5. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–π—Ç–µ credentials –∑ Key Vault
            ### –¢–∞–±–ª–∏—Ü—ñ:
            - `dbo.Sales` - –¥–∞–Ω—ñ –ø—Ä–æ–¥–∞–∂—ñ–≤
            - `dbo.Customers` - –∫–ª—ñ—î–Ω—Ç–∏
            - `dbo.Products` - –ø—Ä–æ–¥—É–∫—Ç–∏
            ### –í—ñ–¥–ø–æ–≤—ñ–¥–∞–ª—å–Ω–∏–π: –ü–µ—Ç—Ä–æ–≤ –ü.–ü.
            ### üìû –ö–æ–Ω—Ç–∞–∫—Ç: petrov@company.com
            """)
    elif source_type == "OData (1–°)":
        st.subheader("üîó OData –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ 1–°")
        with st.expander("üìç 1–° Production OData", expanded=True):
            st.markdown("""
            ### Endpoint URL:
            ```
            https://1c-server.company.local/production/odata/standard.odata/
            ```
            ### –ê–≤—Ç–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—è:
            - **–¢–∏–ø:** Basic Authentication
            - **Username:** –ó–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤ Key Vault (`1c-odata-username`)
            - **Password:** –ó–±–µ—Ä—ñ–≥–∞—î—Ç—å—Å—è –≤ Key Vault (`1c-odata-password`)
            
            ### –Ø–∫ –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –∑ Fabric:
            1. –°—Ç–≤–æ—Ä—ñ—Ç—å –Ω–æ–≤–∏–π Data Source
            2. –û–±–µ—Ä—ñ—Ç—å "OData"
            3. –í–≤–µ–¥—ñ—Ç—å URL endpoint
            4. –û–±–µ—Ä—ñ—Ç—å Basic Authentication
            5. –í–≤–µ–¥—ñ—Ç—å credentials

            ### –î–æ—Å—Ç—É–ø–Ω—ñ –µ–Ω–¥–ø–æ—ñ–Ω—Ç–∏:
            - `Catalog_–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞` - –¥–æ–≤—ñ–¥–Ω–∏–∫ –Ω–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∏
            - `Document_–†–µ–∞–ª—ñ–∑–∞—Ü—ñ—è–¢–æ–≤–∞—Ä—ñ–≤–¢–∞–ü–æ—Å–ª—É–≥` - –¥–æ–∫—É–º–µ–Ω—Ç–∏ –ø—Ä–æ–¥–∞–∂—ñ–≤
            - `InformationRegister_–ó–∞–ª–∏—à–∫–∏–¢–æ–≤–∞—Ä—ñ–≤` - –∑–∞–ª–∏—à–∫–∏ —Ç–æ–≤–∞—Ä—ñ–≤
            
            ### ‚ö†Ô∏è –û–±–º–µ–∂–µ–Ω–Ω—è:
            - –ú–∞–∫—Å–∏–º—É–º 1000 –∑–∞–ø–∏—Å—ñ–≤ –∑–∞ –∑–∞–ø–∏—Ç (–≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É–π—Ç–µ $top —ñ $skip)
            - Rate limit: 100 –∑–∞–ø–∏—Ç—ñ–≤ –Ω–∞ —Ö–≤–∏–ª–∏–Ω—É
            
            ### üí° –ü—Ä–∏–∫–ª–∞–¥ –∑–∞–ø–∏—Ç—É:
            ```
            GET /Catalog_–ù–æ–º–µ–Ω–∫–ª–∞—Ç—É—Ä–∞?$top=100&$select=Code,Description
            ```
            ### –í—ñ–¥–ø–æ–≤—ñ–¥–∞–ª—å–Ω–∏–π: –°–∏–¥–æ—Ä–æ–≤ –°.–°.
            ### üìû –ö–æ–Ω—Ç–∞–∫—Ç: sidorov@company.com
            """)
    else:
        st.info("–û–±–µ—Ä—ñ—Ç—å —Ç–∏–ø –¥–∂–µ—Ä–µ–ª–∞ –∑—ñ —Å–ø–∏—Å–∫—É –≤–∏—â–µ, —â–æ–± –ø–æ–±–∞—á–∏—Ç–∏ –¥–µ—Ç–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é")

# ==================== TROUBLESHOOTING ====================
elif section == "üÜò Troubleshooting":
    st.header("üÜò –í–∏—Ä—ñ—à–µ–Ω–Ω—è –ø—Ä–æ–±–ª–µ–º")
    st.markdown("–¢—É—Ç –∑—ñ–±—Ä–∞–Ω—ñ –Ω–∞–π—á–∞—Å—Ç—ñ—à—ñ –ø—Ä–æ–±–ª–µ–º–∏ —Ç–∞ —ó—Ö —Ä—ñ—à–µ–Ω–Ω—è")
    problem = st.selectbox(
        "–û–±–µ—Ä—ñ—Ç—å –ø—Ä–æ–±–ª–µ–º—É:",
        [
            "–û–±–µ—Ä—ñ—Ç—å –ø—Ä–æ–±–ª–µ–º—É...",
            "Pipeline –ø–∞–¥–∞—î –∑ –ø–æ–º–∏–ª–∫–æ—é",
            "–î–∞–Ω—ñ –Ω–µ –æ–Ω–æ–≤–ª—é—é—Ç—å—Å—è",
            "–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –¥–∂–µ—Ä–µ–ª–∞",
            "Power BI –∑–≤—ñ—Ç –ø–æ–∫–∞–∑—É—î —Å—Ç–∞—Ä—ñ –¥–∞–Ω—ñ",
            "–ü–æ–≤—ñ–ª—å–Ω–µ –æ–Ω–æ–≤–ª–µ–Ω–Ω—è",
            "–ü–æ–º–∏–ª–∫–∏ –∞–≤—Ç–µ–Ω—Ç–∏—Ñ—ñ–∫–∞—Ü—ñ—ó"
        ]
    )
    if problem == "Pipeline –ø–∞–¥–∞—î –∑ –ø–æ–º–∏–ª–∫–æ—é":
        st.error("### ‚ùå Pipeline –ø–∞–¥–∞—î –∑ –ø–æ–º–∏–ª–∫–æ—é")
        with st.expander("üí° –†—ñ—à–µ–Ω–Ω—è 1: –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –ª–æ–≥–∏", expanded=True):
            st.markdown("""
            ### –Ø–∫ –ø–æ–¥–∏–≤–∏—Ç–∏—Å—è –ª–æ–≥–∏:
            1. –í—ñ–¥–∫—Ä–∏–π—Ç–µ Fabric
            2. –ó–Ω–∞–π–¥—ñ—Ç—å –≤–∞—à pipeline
            3. –í—ñ–¥–∫—Ä–∏–π—Ç–µ —ñ—Å—Ç–æ—Ä—ñ—é –∑–∞–ø—É—Å–∫—ñ–≤ (Run history)
            4. –ö–ª—ñ–∫–Ω—ñ—Ç—å –Ω–∞ –ø—Ä–æ–±–ª–µ–º–Ω–∏–π –∑–∞–ø—É—Å–∫
            5. –ü–µ—Ä–µ–≥–ª—è–Ω—å—Ç–µ –¥–µ—Ç–∞–ª—å–Ω—ñ –ª–æ–≥–∏
            
            ### –©–æ —à—É–∫–∞—Ç–∏ –≤ –ª–æ–≥–∞—Ö:
            - üî¥ **"Timeout"** ‚Üí –¥–∂–µ—Ä–µ–ª–æ –Ω–µ –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î, –ø–µ—Ä–µ–≤—ñ—Ä—Ç–µ –¥–æ—Å—Ç—É–ø–Ω—ñ—Å—Ç—å
            - üî¥ **"Authentication failed"** ‚Üí –ø—Ä–æ–±–ª–µ–º–∞ –∑ credentials
            - üî¥ **"Permission denied"** ‚Üí –Ω–µ–º–∞—î –ø—Ä–∞–≤ –¥–æ—Å—Ç—É–ø—É
            - üî¥ **"Schema mismatch"** ‚Üí —Å—Ç—Ä—É–∫—Ç—É—Ä–∞ –¥–∞–Ω–∏—Ö –∑–º—ñ–Ω–∏–ª–∞—Å—è
            """)
        with st.expander("üí° –†—ñ—à–µ–Ω–Ω—è 2: –ü–µ—Ä–µ–∑–∞–ø—É—Å—Ç—ñ—Ç—å pipeline"):
            st.markdown("""
            ### –ö—Ä–æ–∫–∏:
            1. –î–æ—á–µ–∫–∞–π—Ç–µ—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–Ω—è –ø–æ—Ç–æ—á–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫—É (–Ω–∞–≤—ñ—Ç—å —è–∫—â–æ –≤—ñ–Ω –∑ –ø–æ–º–∏–ª–∫–æ—é)
            2. –ù–∞—Ç–∏—Å–Ω—ñ—Ç—å "Run again"
            3. –Ø–∫—â–æ –ø—Ä–æ–±–ª–µ–º–∞ –ø–æ–≤—Ç–æ—Ä—é—î—Ç—å—Å—è - –¥–∏–≤—ñ—Ç—å—Å—è —ñ–Ω—à—ñ —Ä—ñ—à–µ–Ω–Ω—è
            """)
        with st.expander("üí° –†—ñ—à–µ–Ω–Ω—è 3: –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ –¥–∂–µ—Ä–µ–ª–æ –¥–∞–Ω–∏—Ö"):
            st.markdown("""
            ### –Ø–∫ –ø–µ—Ä–µ–≤—ñ—Ä–∏—Ç–∏:
            1. –°–ø—Ä–æ–±—É–π—Ç–µ –ø—ñ–¥–∫–ª—é—á–∏—Ç–∏—Å—è –¥–æ –¥–∂–µ—Ä–µ–ª–∞ –≤—Ä—É—á–Ω—É
            2. –í–∏–∫–æ–Ω–∞–π—Ç–µ –ø—Ä–æ—Å—Ç–∏–π –∑–∞–ø–∏—Ç
            3. –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —á–∏ –¥–æ—Å—Ç—É–ø–Ω–∏–π —Å–µ—Ä–≤–µ—Ä
            
            ### –Ü–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç–∏ –¥–ª—è –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏:
            - SQL Server: SQL Server Management Studio
            - OData: –±—Ä–∞—É–∑–µ—Ä –∞–±–æ Postman
            - API: Postman –∞–±–æ curl
            """)
    elif problem == "–î–∞–Ω—ñ –Ω–µ –æ–Ω–æ–≤–ª—é—é—Ç—å—Å—è":
        st.error("### ‚ö†Ô∏è –î–∞–Ω—ñ –Ω–µ –æ–Ω–æ–≤–ª—é—é—Ç—å—Å—è")
        st.markdown("""
        ### –ß–µ–∫–ª–∏—Å—Ç –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏:
        """)
        check1 = st.checkbox("‚úì Pipeline –≤–∏–∫–æ–Ω–∞–≤—Å—è —É—Å–ø—ñ—à–Ω–æ (–±–µ–∑ –ø–æ–º–∏–ª–æ–∫)")
        check2 = st.checkbox("‚úì –í –¥–∂–µ—Ä–µ–ª—ñ —î –Ω–æ–≤—ñ –¥–∞–Ω—ñ")
        check3 = st.checkbox("‚úì Dataset –≤ Power BI –æ–Ω–æ–≤–ª–µ–Ω–æ –ø—ñ—Å–ª—è pipeline")
        check4 = st.checkbox("‚úì –ü–µ—Ä–µ–≤—ñ—Ä–∏–≤ —Ñ—ñ–ª—å—Ç—Ä–∏ –≤ –∑–≤—ñ—Ç—ñ (–º–æ–∂–ª–∏–≤–æ, –≤—ñ–¥—Ñ—ñ–ª—å—Ç—Ä–æ–≤–∞–Ω—ñ –Ω–æ–≤—ñ –¥–∞–Ω—ñ)")
        check5 = st.checkbox("‚úì –û—á–∏—Å—Ç–∏–≤ –∫–µ—à –±—Ä–∞—É–∑–µ—Ä–∞")
        if all([check1, check2, check3, check4, check5]):
            st.success("–Ø–∫—â–æ –≤—Å—ñ –ø—É–Ω–∫—Ç–∏ –≤–∏–∫–æ–Ω–∞–Ω—ñ, –∞–ª–µ –¥–∞–Ω—ñ –≤—Å–µ –æ–¥–Ω–æ —Å—Ç–∞—Ä—ñ - –∑–≤–µ—Ä–Ω—ñ—Ç—å—Å—è –¥–æ IT Support")
    elif problem == "–ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –¥–∂–µ—Ä–µ–ª–∞":
        st.error("### üîå –ü–æ–º–∏–ª–∫–∞ –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è –¥–æ –¥–∂–µ—Ä–µ–ª–∞")
        st.markdown("""
        ### –ú–æ–∂–ª–∏–≤—ñ –ø—Ä–∏—á–∏–Ω–∏:
        1. **–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ñ credentials**
           - –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ Key Vault
           - –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —á–∏ –Ω–µ –∑–∞–∫—ñ–Ω—á–∏–≤—Å—è —Ç–µ—Ä–º—ñ–Ω –¥—ñ—ó –ø–∞—Ä–æ–ª—é
        2. **–î–∂–µ—Ä–µ–ª–æ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–µ**
           - –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —á–∏ –ø—Ä–∞—Ü—é—î —Å–µ—Ä–≤–µ—Ä
           - –ú–æ–∂–ª–∏–≤–æ, –ø—Ä–æ–≤–æ–¥—è—Ç—å—Å—è —Ç–µ—Ö–Ω—ñ—á–Ω—ñ —Ä–æ–±–æ—Ç–∏
           - –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ firewall rules
        3. **–ú–µ—Ä–µ–∂–µ–≤—ñ –ø—Ä–æ–±–ª–µ–º–∏**
           - –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ VPN –ø—ñ–¥–∫–ª—é—á–µ–Ω–Ω—è
           - –ü–µ—Ä–µ–≤—ñ—Ä—Ç–µ, —á–∏ IP Fabric –¥–æ–¥–∞–Ω–æ –¥–æ whitelist
        4. **–ó–∞–∫—ñ–Ω—á–∏–ª–∏—Å—è –ª—ñ–º—ñ—Ç–∏**
           - –ú–æ–∂–ª–∏–≤–æ, –ø–µ—Ä–µ–≤–∏—â–µ–Ω–æ –ª—ñ–º—ñ—Ç –∑–∞–ø–∏—Ç—ñ–≤ –¥–æ API
           - –ó–∞—á–µ–∫–∞–π—Ç–µ 15-30 —Ö–≤–∏–ª–∏–Ω —Ç–∞ —Å–ø—Ä–æ–±—É–π—Ç–µ –∑–Ω–æ–≤—É
        """)
    else:
        st.info("–û–±–µ—Ä—ñ—Ç—å –ø—Ä–æ–±–ª–µ–º—É –∑—ñ —Å–ø–∏—Å–∫—É –≤–∏—â–µ, —â–æ–± –ø–æ–±–∞—á–∏—Ç–∏ —Ä—ñ—à–µ–Ω–Ω—è")
    st.markdown("---")
    st.warning("""
    ### üÜò –Ø–∫—â–æ –Ω—ñ—á–æ–≥–æ –Ω–µ –¥–æ–ø–æ–º–æ–≥–ª–æ:
    1. **–ó–∞—Ç–µ–ª–µ—Ñ–æ–Ω—É–π—Ç–µ –¥–æ IT Support:** +380 XX XXX-XX-XX
    2. **–ù–∞–ø–∏—à—ñ—Ç—å –≤ Teams:** –∫–∞–Ω–∞–ª #data-engineering-support
    3. **Email:** support@company.com
    ### ‚ùó –ï–∫—Å—Ç—Ä–µ–Ω—ñ —Å–∏—Ç—É–∞—Ü—ñ—ó (–∑–≤—ñ—Ç–∏ –¥–ª—è –∫–µ—Ä—ñ–≤–Ω–∏—Ü—Ç–≤–∞ –Ω–µ –ø—Ä–∞—Ü—é—é—Ç—å):
    - –¢–µ–ª–µ—Ñ–æ–Ω —Ç–µ—Ö–Ω—ñ—á–Ω–æ–≥–æ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∞: +380 XX XXX-XX-XX
    - Telegram: @tech_director
    """)

# ==================== –ö–û–ù–¢–ê–ö–¢–ò ====================
elif section == "üìû –ö–æ–Ω—Ç–∞–∫—Ç–∏ —Ç–∞ —Ä–µ—Å—É—Ä—Å–∏":
    st.header("üìû –ö–æ–Ω—Ç–∞–∫—Ç–∏ —Ç–∞ —Ä–µ—Å—É—Ä—Å–∏")
    st.subheader("üë• –ö–æ–º–∞–Ω–¥–∞")
    col1, col2 = st.columns(2)
    with col1:
        st.markdown("""
        ### Data Engineering Team

        **–Ü–≤–∞–Ω–æ–≤ –Ü–≤–∞–Ω –Ü–≤–∞–Ω–æ–≤–∏—á**  
        Data Engineer (Lake/Pipeline)  
        üìß ivanov@company.com  
        üì± +380 XX XXX-XX-XX  
        üí¨ Teams: @ivanov

        ---

        **–ü–µ—Ç—Ä–æ–≤ –ü–µ—Ç—Ä–æ –ü–µ—Ç—Ä–æ–≤–∏—á**  
        Data Engineer (Power BI)  
        üìß petrov@company.com  
        üì± +380 XX XXX-XX-XX  
        üí¨ Teams: @petrov
        """)
    with col2:
        st.markdown("""
        ### IT Support

        **–°–∏–¥–æ—Ä–æ–≤ –°–µ—Ä–≥—ñ–π –°–µ—Ä–≥—ñ–π–æ–≤–∏—á**  
        System Administrator  
        üìß sidorov@company.com  
        üì± +380 XX XXX-XX-XX  
        üí¨ Teams: @sidorov

        ---

        **IT Support –∑–∞–≥–∞–ª—å–Ω–∏–π**  
        üìß support@company.com  
        üì± +380 XX XXX-XX-XX (–≥–∞—Ä—è—á–∞ –ª—ñ–Ω—ñ—è)  
        üïê –ü–Ω-–ü—Ç: 9:00-18:00
        """)
    st.markdown("---")
    st.subheader("üîó –ö–æ—Ä–∏—Å–Ω—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è")
    st.markdown("""
    ### –†–æ–±–æ—á—ñ —Å–∏—Å—Ç–µ–º–∏:
    - üåê [Microsoft Fabric Portal](https://fabric.microsoft.com)
    - üìä [Power BI Service](https://app.powerbi.com)
    - üîê [Azure Key Vault](https://portal.azure.com)
    - üìÇ [SharePoint - –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è](https://company.sharepoint.com/documentation)
    
    ### –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è:
    - üìö [Microsoft Fabric Docs](https://learn.microsoft.com/fabric/)
    - üìö [Power BI Docs](https://learn.microsoft.com/power-bi/)
    - üìö [–í–Ω—É—Ç—Ä—ñ—à–Ω—è Wiki](https://wiki.company.local)
    
    ### –î–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è:
    - üéì [Microsoft Learn - Fabric](https://learn.microsoft.com/training/fabric/)
    - üéì [Power BI Training](https://learn.microsoft.com/training/powerplatform/power-bi)
    - üé• [–í—ñ–¥–µ–æ —É—Ä–æ–∫–∏ (–≤–Ω—É—Ç—Ä—ñ—à–Ω—ñ)](https://company.sharepoint.com/videos)
    """)
    st.markdown("---")
    st.subheader("üìù –®–∞–±–ª–æ–Ω–∏ —Ç–∞ —Å–∫—Ä–∏–ø—Ç–∏")
    with st.expander("üíæ –®–∞–±–ª–æ–Ω connection string –¥–ª—è SQL"):
        st.code("""
Server=YOUR_SERVER.database.windows.net;
Database=YOUR_DATABASE;
Authentication=Active Directory Integrated;
        """, language="text")
    with st.expander("üíæ –®–∞–±–ª–æ–Ω –∑–∞–ø–∏—Ç—É –¥–æ OData"):
        st.code("""
GET https://your-endpoint/EntityName?$top=100&$skip=0&$select=Field1,Field2&$filter=Date gt 2025-01-01
        """, language="text")
    with st.expander("üíæ –°–∫—Ä–∏–ø—Ç –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏ –¥–∞–Ω–∏—Ö –≤ Lake"):
        st.code("""
SELECT 
    COUNT(*) as total_records,
    MAX(LoadDate) as last_load_date,
    MIN(LoadDate) as first_load_date,
    COUNT(DISTINCT CustomerID) as unique_customers
FROM Sales_Lake.FactSales
WHERE LoadDate >= DATEADD(day, -7, GETDATE())
        """, language="sql")

st.markdown("---")
st.markdown("""
<div style='text-align: center; color: gray;'>
    üìö –ë–∞–∑–∞ –∑–Ω–∞–Ω—å Data Engineering Team | –í–µ—Ä—Å—ñ—è 1.0 | –ñ–æ–≤—Ç–µ–Ω—å 2025
</div>
""", unsafe_allow_html=True)
